

Objective 1 - Regression Models


Starting new Tests



Tree Regressor Selection

\begin{tabular}{lllllrrr}
 &  &  &  &  & mae & rve & r2 \\
criterion & max_depth & min_samples_leaf & min_samples_split & max_leaf_nodes &  &  &  \\
\multirow[c]{16}{*}{squared\_error} & \multirow[c]{8}{*}{nan} & \multirow[c]{4}{*}{1} & \multirow[c]{2}{*}{2} & nan & 3.733 & 0.462 & 0.460 \\
 &  &  &  & 40.000000 & 3.629 & 0.537 & 0.536 \\
 &  &  & \multirow[c]{2}{*}{4} & nan & 3.657 & 0.483 & 0.482 \\
 &  &  &  & 40.000000 & 3.618 & 0.541 & 0.540 \\
 &  & \multirow[c]{4}{*}{3} & \multirow[c]{2}{*}{2} & nan & 3.666 & 0.517 & 0.515 \\
 &  &  &  & 40.000000 & 3.619 & 0.548 & 0.547 \\
 &  &  & \multirow[c]{2}{*}{4} & nan & 3.658 & 0.516 & 0.515 \\
 &  &  &  & 40.000000 & 3.617 & 0.550 & 0.549 \\
 & \multirow[c]{8}{*}{10.000000} & \multirow[c]{4}{*}{1} & \multirow[c]{2}{*}{2} & nan & 3.664 & 0.487 & 0.485 \\
 &  &  &  & 40.000000 & 3.604 & 0.544 & 0.543 \\
 &  &  & \multirow[c]{2}{*}{4} & nan & 3.609 & 0.508 & 0.506 \\
 &  &  &  & 40.000000 & 3.590 & 0.547 & 0.546 \\
 &  & \multirow[c]{4}{*}{3} & \multirow[c]{2}{*}{2} & nan & 3.630 & 0.531 & 0.529 \\
 &  &  &  & 40.000000 & 3.609 & 0.550 & 0.549 \\
 &  &  & \multirow[c]{2}{*}{4} & nan & 3.638 & 0.525 & 0.524 \\
 &  &  &  & 40.000000 & 3.610 & 0.548 & 0.546 \\
\multirow[c]{16}{*}{friedman\_mse} & \multirow[c]{8}{*}{nan} & \multirow[c]{4}{*}{1} & \multirow[c]{2}{*}{2} & nan & 3.738 & 0.464 & 0.463 \\
 &  &  &  & 40.000000 & 3.641 & 0.533 & 0.532 \\
 &  &  & \multirow[c]{2}{*}{4} & nan & 3.696 & 0.470 & 0.469 \\
 &  &  &  & 40.000000 & 3.609 & 0.542 & 0.541 \\
 &  & \multirow[c]{4}{*}{3} & \multirow[c]{2}{*}{2} & nan & 3.658 & 0.520 & 0.518 \\
 &  &  &  & 40.000000 & 3.629 & 0.543 & 0.542 \\
 &  &  & \multirow[c]{2}{*}{4} & nan & 3.659 & 0.517 & 0.516 \\
 &  &  &  & 40.000000 & 3.615 & 0.550 & 0.549 \\
 & \multirow[c]{8}{*}{10.000000} & \multirow[c]{4}{*}{1} & \multirow[c]{2}{*}{2} & nan & 3.668 & 0.486 & 0.484 \\
 &  &  &  & 40.000000 & 3.610 & 0.544 & 0.543 \\
 &  &  & \multirow[c]{2}{*}{4} & nan & 3.628 & 0.498 & 0.497 \\
 &  &  &  & 40.000000 & 3.577 & 0.552 & 0.550 \\
 &  & \multirow[c]{4}{*}{3} & \multirow[c]{2}{*}{2} & nan & 3.619 & 0.529 & 0.528 \\
 &  &  &  & 40.000000 & 3.620 & 0.544 & 0.543 \\
 &  &  & \multirow[c]{2}{*}{4} & nan & 3.626 & 0.530 & 0.529 \\
 &  &  &  & 40.000000 & 3.612 & 0.547 & 0.545 \\
\end{tabular}

 --- 


Ridge Selection

\begin{tabular}{lrrr}
 & mae & rve & r2 \\
alpha &  &  &  \\
0.000010 & 6.422 & 0.121 & 0.120 \\
0.000100 & 6.422 & 0.121 & 0.120 \\
0.001000 & 6.422 & 0.121 & 0.120 \\
0.010000 & 6.422 & 0.121 & 0.120 \\
0.100000 & 6.422 & 0.121 & 0.120 \\
1.000000 & 6.422 & 0.121 & 0.120 \\
10.000000 & 6.424 & 0.123 & 0.122 \\
\end{tabular}

 --- 


Lasso Selection

\begin{tabular}{lrrr}
 & mae & rve & r2 \\
alpha &  &  &  \\
0.000010 & 6.422 & 0.121 & 0.120 \\
0.000100 & 6.422 & 0.121 & 0.120 \\
0.001000 & 6.423 & 0.121 & 0.120 \\
0.010000 & 6.439 & 0.122 & 0.121 \\
0.100000 & 6.697 & 0.077 & 0.077 \\
1.000000 & 6.939 & 0.000 & -0.001 \\
10.000000 & 6.939 & 0.000 & -0.001 \\
\end{tabular}

 --- 


Best Model: tree-friedman_mse-10-1-4-40
Best Model Results: {'mae': 3.577337308702566, 'rve': 0.5516590899170477, 'r2': 0.5502283056108465}

-----

Objective 2 - Binary Classification Models



Tree Classifier Selection

\begin{tabular}{lllrrrr}
 &  &  & acc & f1 & recall & precision \\
criterion & max_depth & min_samples_split &  &  &  &  \\
\multirow[c]{4}{*}{gini} & \multirow[c]{2}{*}{40.000000} & 2 & 0.870 & 0.618 & 0.623 & 0.614 \\
 &  & 4 & 0.867 & 0.620 & 0.641 & 0.602 \\
 & \multirow[c]{2}{*}{nan} & 2 & 0.872 & 0.623 & 0.624 & 0.622 \\
 &  & 4 & 0.867 & 0.620 & 0.644 & 0.599 \\
\multirow[c]{4}{*}{entropy} & \multirow[c]{2}{*}{40.000000} & 2 & 0.871 & 0.617 & 0.619 & 0.619 \\
 &  & 4 & 0.870 & 0.623 & 0.636 & 0.613 \\
 & \multirow[c]{2}{*}{nan} & 2 & 0.873 & 0.621 & 0.618 & 0.627 \\
 &  & 4 & 0.870 & 0.620 & 0.628 & 0.614 \\
\multirow[c]{4}{*}{log\_loss} & \multirow[c]{2}{*}{40.000000} & 2 & 0.874 & 0.628 & 0.627 & 0.630 \\
 &  & 4 & 0.870 & 0.619 & 0.627 & 0.614 \\
 & \multirow[c]{2}{*}{nan} & 2 & 0.874 & 0.627 & 0.626 & 0.628 \\
 &  & 4 & 0.871 & 0.621 & 0.628 & 0.617 \\
\end{tabular}

 --- 


Best Model: tree-log_loss-40-2
Best Model Results: {'acc': 0.8742080378250592, 'f1': 0.6275214563416871, 'recall': 0.6270398145209232, 'precision': 0.629762386027005}

-----



Independent Validation Set - Final Conclusions:




format of the model name:
 - model_type(tree vs linear vs ...), criterions, splitters, max_depths

 - model_type(tree vs linear vs ...), criterions, splitters, max_depths, max_features, min_samples_leaf, min_samples_splits, max_leaf_nodes


--- Regressor ---
Model: tree-friedman_mse-10-1-4-40
Performance on IVS: {'mae': 0.44971198663826745, 'rve': 0.5430503832050402, 'pearson_corr': (0.7503882416563327, 3.853807369440189e-213)}
MAE (re-scaled): 3.646189254263551 
RVE: 0.5430503832050402
Pearson Correlation Score: (0.7503882416563327, 3.853807369440189e-213)

--- Classifier ---
Model: tree-log_loss-40-2
Performance on IVS: {'acc': 0.9225531914893617, 'f1': 0.7908045977011495, 'recall': 0.819047619047619, 'precision': 0.7644444444444445, 'matthews_corr': 0.7440204008509572, 'confusion_matrix': array([[912,  53],
       [ 38, 172]], dtype=int64)}
Accuracy: 0.9225531914893617
F1: 0.7908045977011495
Precision: 0.7644444444444445
Recall: 0.819047619047619
Matthews Correlation Coefficient: 0.7440204008509572
Confusion Matrix:
     0    1
0  912   53
1   38  172


--------------------------------------------------------------------------------------------------------------------------------------------------------

