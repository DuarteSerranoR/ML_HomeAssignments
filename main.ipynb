{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from enum import Enum\n",
    "import json\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error, max_error, mean_absolute_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Dataset preparation\n",
    "### 1.1.1. Shuffle and Split into training and IVS\n",
    "- `train_df` -- training set for model training/selection\n",
    "- `ivs_df` -- independet validation set (IVS) for the final benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)\n",
    "train_size = int(0.8 * n)\n",
    "train_df = df.iloc[:train_size]\n",
    "ivs_df = df.iloc[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. Analyzing the Data Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(train_df[['Jitter(Abs)', 'Shimmer', 'NHR', 'HNR', 'RPDE', 'DFA', 'PPE']])\n",
    "train_y = np.array(train_df[\"motor_UPDRS\"])\n",
    "ivs_x = np.array(ivs_df.drop([\"subject#\", \"age\", \"sex\", \"test_time\", \"motor_UPDRS\", \"total_UPDRS\"], axis=1))\n",
    "ivs_y = np.array(ivs_df[\"motor_UPDRS\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"squared_error-best-3\": [\n",
      "        {\n",
      "            \"mae\": 9.14460945135377,\n",
      "            \"rve\": -0.9812084426630414\n",
      "        },\n",
      "        {\n",
      "            \"mae\": 7.731570121805598,\n",
      "            \"rve\": -0.004883559452879771\n",
      "        },\n",
      "        {\n",
      "            \"mae\": 8.57498559421701,\n",
      "            \"rve\": -0.24235183734294385\n",
      "        },\n",
      "        {\n",
      "            \"mae\": 8.588457783088712,\n",
      "            \"rve\": -0.8192318073717832\n",
      "        },\n",
      "        {\n",
      "            \"mae\": 8.61314601433357,\n",
      "            \"rve\": -0.39789037155257434\n",
      "        }\n",
      "    ],\n",
      "    \"squared_error-best-4\": [\n",
      "        {\n",
      "            \"mae\": 8.941997178205796,\n",
      "            \"rve\": -0.9468426733270665\n",
      "        },\n",
      "        {\n",
      "            \"mae\": 7.804415849089664,\n",
      "            \"rve\": -0.02261655359532755\n",
      "        },\n",
      "        {\n",
      "            \"mae\": 9.208440697969555,\n",
      "            \"rve\": -0.33308881246691047\n",
      "        },\n",
      "        {\n",
      "            \"mae\": 8.119310853348297,\n",
      "            \"rve\": -0.7009597997679424\n",
      "        },\n",
      "        {\n",
      "            \"mae\": 8.54697003155055,\n",
      "            \"rve\": -0.45174360833537275\n",
      "        }\n",
      "    ],\n",
      "    \"squared_error-best-12\": [\n",
      "        {\n",
      "            \"mae\": 9.486036907174995,\n",
      "            \"rve\": -1.248638524155338\n",
      "        },\n",
      "        {\n",
      "            \"mae\": 8.141564594602915,\n",
      "            \"rve\": -0.21263852455763566\n",
      "        },\n",
      "        {\n",
      "            \"mae\": 10.648279648159432,\n",
      "            \"rve\": -1.0981283495446372\n",
      "        },\n",
      "        {\n",
      "            \"mae\": 9.291713316436967,\n",
      "            \"rve\": -1.198153804396214\n",
      "        },\n",
      "        {\n",
      "            \"mae\": 9.450942659719743,\n",
      "            \"rve\": -0.8834813340782675\n",
      "        }\n",
      "    ],\n",
      "    \"squared_error-best-None\": [\n",
      "        {\n",
      "            \"mae\": 9.330733590425533,\n",
      "            \"rve\": -1.2058196153003231\n",
      "        },\n",
      "        {\n",
      "            \"mae\": 8.12092710106383,\n",
      "            \"rve\": -0.22420394643754893\n",
      "        },\n",
      "        {\n",
      "            \"mae\": 10.435834627659574,\n",
      "            \"rve\": -1.1221014614838807\n",
      "        },\n",
      "        {\n",
      "            \"mae\": 9.236723909574469,\n",
      "            \"rve\": -1.1869700686468936\n",
      "        },\n",
      "        {\n",
      "            \"mae\": 9.441686755319148,\n",
      "            \"rve\": -0.8836326405159023\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def simple_cross_validation(*, model, x, y, train_partition=(0, 0.8), metrics={\"mae\": mean_absolute_error}):\n",
    "    n, m = x.shape\n",
    "    \n",
    "    start = int(train_partition[0] * n)\n",
    "    end = int(train_partition[1] * n)\n",
    "    \n",
    "    x_train = x[start:end, :]\n",
    "    y_train = y[start:end]\n",
    "    x_test = np.concatenate((x[:start, :], x[end:, :]))\n",
    "    y_test = np.concatenate((y[:start], y[end:]))\n",
    "    \n",
    "    #print(\"SCV\")\n",
    "    #print(x_train)\n",
    "    #print(y_train)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    return {metric_name: metric_f(y_test, y_pred) for (metric_name, metric_f) in metrics.items()}\n",
    "\n",
    "\n",
    "def kfold(*, model, x, y, k=5, metrics):\n",
    "    n, m = x.shape\n",
    "    results = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        start = i * (1/k)\n",
    "        end = start + (1/k)\n",
    "        if (i + 1) == k:\n",
    "            end = 1.0\n",
    "            \n",
    "        result = simple_cross_validation(model=model, x=x, y=y, train_partition=(start, end), metrics=metrics)\n",
    "        \n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def model_selection(x: np.ndarray, y: np.ndarray):\n",
    "    \n",
    "    # Split into train and test\n",
    "    n, m = x.shape\n",
    "    partition = int(0.8 * n)\n",
    "    x_train = x[:partition, :]\n",
    "    x_test = x[partition:, :]\n",
    "    y_train = y[:partition]\n",
    "    y_test = y[partition:]\n",
    "    \n",
    "    # Hyperparameters\n",
    "    criterions = [\"squared_error\"]\n",
    "    splitters = [\"best\"]\n",
    "    max_depths = [3, 4, 12, None]\n",
    "    hyper_parameters = product(criterions, splitters, max_depths)\n",
    "    \n",
    "    results_l = []\n",
    "    \n",
    "    for p in hyper_parameters:\n",
    "        criterion, splitter, max_depth = p\n",
    "        \n",
    "        model = tree.DecisionTreeRegressor(criterion=criterion,\n",
    "                                           splitter=splitter,\n",
    "                                           max_depth=max_depth)\n",
    "        \n",
    "        \n",
    "        # Use either simple_cross_validation or kfold below\n",
    "        #result = simple_cross_validation(model=model, x=x, y=y, metrics={\"mae\": mean_absolute_error, \"rve\": explained_variance_score})\n",
    "        result = kfold(model=model, x=x, y=y, k=5, metrics={\"mae\": mean_absolute_error, \"rve\": explained_variance_score})\n",
    "        \n",
    "        results[p] = {\"model\": model, \"evaluation\": result}\n",
    "        \n",
    "    # TODO: select the best model and return it\n",
    "    return results\n",
    "\n",
    "results = model_selection(train_x, train_y)\n",
    "print(json.dumps({\"-\".join([str(p) for p in k]): v[\"evaluation\"] for (k, v) in results.items()}, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Validate against IVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae': 7.475312481127658, 'rve': -0.4144267646280848}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# TODO \\n# Example of selected model. This should be trained on the complete train data set\\nselected_model = results[(\"squared_error\",\"best\",3)][\"model\"]\\n\\ndef validate_agains_ivs(*, model, ivs_x, ivs_y, metrics={\"mae\": mean_absolute_error, \"rve\": explained_variance_score}):\\n    y_pred = model.predict(ivs_x)\\n    \\n    plt.xlim(10, 40)\\n    plt.ylim(10, 40)\\n    plt.axline((0, 0), slope=1, color=\"black\")\\n    plt.plot(y_pred, ivs_y, \".\")\\n    \\n    return {metric_name: metric_f(ivs_y, y_pred) for (metric_name, metric_f) in metrics.items()}\\n\\n    \\nperformance_on_ivs = validate_agains_ivs(model=selected_model, ivs_x=ivs_x, ivs_y=ivs_y)\\nprint(performance_on_ivs)\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of selected model. This should be trained on the complete train data set\n",
    "selected_model = results[(\"squared_error\",\"best\",3)][\"model\"]\n",
    "\n",
    "def validate_agains_ivs(*, model, ivs_x, ivs_y, metrics={\"mae\": mean_absolute_error, \"rve\": explained_variance_score}):\n",
    "    y_pred = model.predict(ivs_x)\n",
    "    \n",
    "    plt.xlim(-2, 2)\n",
    "    plt.ylim(-2, 2)\n",
    "    plt.axline((0, 0), slope=1, color=\"black\")\n",
    "    plt.plot(y_pred, ivs_y, \".\")\n",
    "    \n",
    "    return {metric_name: metric_f(ivs_y, y_pred) for (metric_name, metric_f) in metrics.items()}\n",
    "\n",
    "    \n",
    "performance_on_ivs = validate_agains_ivs(model=selected_model, ivs_x=ivs_x, ivs_y=ivs_y)\n",
    "print(performance_on_ivs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "055142e5cf66ed8ee87e97d9d29944a505c8696ace08c4c3475747b47f85af0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
