{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4564, 42)\n",
      "Number of rows with at least one missing value: 3675\n",
      "Column SpMax_L        has    0 missing values (0%)\n",
      "Column J_Dz(e)        has    0 missing values (0%)\n",
      "Column nHM            has    0 missing values (0%)\n",
      "Column F01            has  515 missing values (11%)\n",
      "Column F04            has    0 missing values (0%)\n",
      "Column NssssC         has    0 missing values (0%)\n",
      "Column nCb            has    0 missing values (0%)\n",
      "Column C              has  767 missing values (17%)\n",
      "Column nCp            has  671 missing values (15%)\n",
      "Column nO             has    0 missing values (0%)\n",
      "Column F03            has    0 missing values (0%)\n",
      "Column SdssC          has    0 missing values (0%)\n",
      "Column HyWi_B         has  479 missing values (10%)\n",
      "Column LOC            has    0 missing values (0%)\n",
      "Column SM6_L          has    0 missing values (0%)\n",
      "Column F03_CO         has   43 missing values (1%)\n",
      "Column Me             has  448 missing values (10%)\n",
      "Column Mi             has    0 missing values (0%)\n",
      "Column nN_N           has    0 missing values (0%)\n",
      "Column nArNO2         has    0 missing values (0%)\n",
      "Column nCRX3          has    0 missing values (0%)\n",
      "Column SpPosA_B       has    0 missing values (0%)\n",
      "Column nCIR           has  490 missing values (11%)\n",
      "Column B01            has    0 missing values (0%)\n",
      "Column B03            has    0 missing values (0%)\n",
      "Column N_073          has    0 missing values (0%)\n",
      "Column SpMax_A        has  674 missing values (15%)\n",
      "Column Psi_i_1d       has    0 missing values (0%)\n",
      "Column B04            has    0 missing values (0%)\n",
      "Column SdO            has  211 missing values (5%)\n",
      "Column TI2_L          has    0 missing values (0%)\n",
      "Column nCrt           has  258 missing values (6%)\n",
      "Column C_026          has    0 missing values (0%)\n",
      "Column F02_CN         has    0 missing values (0%)\n",
      "Column nHDon          has    0 missing values (0%)\n",
      "Column SpMax_B        has 1358 missing values (30%)\n",
      "Column Psi_i_A        has  460 missing values (10%)\n",
      "Column nN             has    0 missing values (0%)\n",
      "Column SM6_B          has    0 missing values (0%)\n",
      "Column nArCOOR        has    0 missing values (0%)\n",
      "Column nX             has  682 missing values (15%)\n",
      "Column Biodegradable  has    0 missing values (0%)\n",
      "Categorical: ['nHM', 'F04', 'NssssC', 'nCb', 'nO', 'F03', 'nN_N', 'nArNO2', 'nCRX3', 'B01', 'B03', 'N_073', 'B04', 'C_026', 'F02_CN', 'nHDon', 'nN', 'nArCOOR']\n",
      "Continuous: ['SpMax_L', 'J_Dz(e)', 'F01', 'C', 'nCp', 'SdssC', 'HyWi_B', 'LOC', 'SM6_L', 'F03_CO', 'Me', 'Mi', 'SpPosA_B', 'nCIR', 'SpMax_A', 'Psi_i_1d', 'SdO', 'TI2_L', 'nCrt', 'SpMax_B', 'Psi_i_A', 'SM6_B', 'nX']\n",
      "Binary: ['B01', 'B03', 'B04']\n",
      "Multicategoric: ['nHM', 'F04', 'NssssC', 'nCb', 'nO', 'F03', 'nN_N', 'nArNO2', 'nCRX3', 'N_073', 'C_026', 'F02_CN', 'nHDon', 'nN', 'nArCOOR']\n",
      "SpMax_L: 0.1338731050104356\n",
      "J_Dz(e): 0.0275724756172826\n",
      "nHM: 0.10445606932109985\n",
      "F01: 0.0\n",
      "F04: 0.07509060195271622\n",
      "NssssC: 0.050855100259034725\n",
      "nCb: 0.07181327558943806\n",
      "C: 0.044995479480420375\n",
      "nCp: 0.0407809848737557\n",
      "nO: 0.018739753748953758\n",
      "F03: 0.0862128565084761\n",
      "SdssC: 0.05266273566343238\n",
      "HyWi_B: 0.06681773699973292\n",
      "LOC: 0.07906881510773034\n",
      "SM6_L: 0.07343097763486717\n",
      "F03_CO: 0.028318181863895564\n",
      "Me: 0.029355967106019065\n",
      "Mi: 0.07066476371953567\n",
      "nN_N: 0.005166902893073422\n",
      "nArNO2: 0.011145820975855925\n",
      "nCRX3: 0.004994395866519508\n",
      "SpPosA_B: 0.06847446624398623\n",
      "nCIR: 0.08335044709072492\n",
      "B01: 0.005323109360586775\n",
      "B03: 0.05786505291441446\n",
      "N_073: 0.026975188509756\n",
      "SpMax_A: 0.10540981213302536\n",
      "Psi_i_1d: 0.11669663966755661\n",
      "B04: 0.009487302891880045\n",
      "SdO: 0.047022400623596194\n",
      "TI2_L: 0.03176425994430421\n",
      "nCrt: 0.014567501177676023\n",
      "C_026: 0.07224783837331472\n",
      "F02_CN: 0.08579089086008307\n",
      "nHDon: 0.02105846778631637\n",
      "SpMax_B: 0.010153233713457777\n",
      "Psi_i_A: 0.05817044183717468\n",
      "nN: 0.08529998965664443\n",
      "SM6_B: 0.0\n",
      "nArCOOR: 0.09429282157029917\n",
      "[0.13387311 0.02757248 0.10445607 0.         0.0750906  0.0508551\n",
      " 0.07181328 0.04499548 0.04078098 0.01873975 0.08621286 0.05266274\n",
      " 0.06681774 0.07906882 0.07343098 0.02831818 0.02935597 0.07066476\n",
      " 0.0051669  0.01114582 0.0049944  0.06847447 0.08335045 0.00532311\n",
      " 0.05786505 0.02697519 0.10540981 0.11669664 0.0094873  0.0470224\n",
      " 0.03176426 0.0145675  0.07224784 0.08579089 0.02105847 0.01015323\n",
      " 0.05817044 0.08529999 0.         0.09429282]\n",
      "0       0.0\n",
      "7       0.0\n",
      "17      0.0\n",
      "26      0.0\n",
      "31      0.0\n",
      "       ... \n",
      "4523    0.0\n",
      "4534    0.0\n",
      "4535    0.0\n",
      "4545    0.0\n",
      "4552    0.0\n",
      "Name: nN_N, Length: 889, dtype: float64\n",
      "0       0.0\n",
      "7       0.0\n",
      "17      0.0\n",
      "26      0.0\n",
      "31      0.0\n",
      "       ... \n",
      "4523    4.0\n",
      "4534    4.0\n",
      "4535    4.0\n",
      "4545    4.0\n",
      "4552    4.0\n",
      "Name: nN_N, Length: 889, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def explain_data():\n",
    "    df = pd.read_csv(\"biodegradable_a.csv\")\n",
    "\n",
    "    print(df.shape)\n",
    "    \n",
    "    n_incomplete_records = df[df.isna().any(axis=1)].shape[0]\n",
    "    print(\"Number of rows with at least one missing value: \" + str(n_incomplete_records))\n",
    "    \n",
    "    for col in df:\n",
    "        n_missing_entries = df[df[col].isna()].shape[0]\n",
    "        print(f\"Column {str(col).ljust(14)} has {str(n_missing_entries).rjust(4)} missing values ({str(round(100*n_missing_entries/df.shape[0]))}%)\")\n",
    "\n",
    "    features = [col for col in df if col != \"Biodegradable\"]\n",
    "\n",
    "    categorical = [col for col in df.drop([\"Biodegradable\"], axis=1) if df[col].apply(lambda x: x.is_integer()).all()]\n",
    "    print(f\"Categorical: {categorical}\")\n",
    "    \n",
    "    continuous = [col for col in df.drop([\"Biodegradable\"], axis=1) if df[col].apply(lambda x: not x.is_integer()).any()]\n",
    "    print(f\"Continuous: {continuous}\")\n",
    "    \n",
    "    binary = [col for col in categorical if df[col].apply(lambda x: x==0 or x==1).all()]\n",
    "    print(f\"Binary: {binary}\")\n",
    "    \n",
    "    multicategoric = [col for col in categorical if df[col].apply(lambda x: x!=0 and x!=1).any()]\n",
    "    print(f\"Multicategoric: {multicategoric}\")\n",
    "    \n",
    "    df = df.dropna()\n",
    "    \n",
    "    x = np.array(df.drop([\"SpMax_B\", \"Biodegradable\"], axis=1))\n",
    "    y = np.array(df[\"Biodegradable\"])\n",
    "    \n",
    "    \n",
    "    mis = mutual_info_classif(x, y, random_state=1)\n",
    "    for (x, mi) in zip(features, mis):\n",
    "        print(f\"{x}: {mi}\")\n",
    "    \n",
    "    print(mis)\n",
    "    print(df[\"nN_N\"])\n",
    "    print(df[\"nN_N\"].cumsum())\n",
    "    \n",
    "explain_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     nHM F04 NssssC nCb nO F03 nN_N nArNO2 nCRX3 B01  ...      nCIR   SpMax_A  \\\n",
      "0      0   0      0   0  0   0    0      0     0   0  ... -0.285357 -0.921040   \n",
      "1      0   0      0   0  1   0    0      0     0   0  ...  0.110875       NaN   \n",
      "2      0   0      0   0  4   0    0      0     0   0  ... -0.285357       NaN   \n",
      "3      0   0      0   0  2   0    0      0     0   0  ... -0.285357 -3.439015   \n",
      "4      0   0      0   0  4   0    0      0     0   0  ...       NaN -0.663410   \n",
      "...   ..  ..    ...  .. ..  ..  ...    ...   ...  ..  ...       ...       ...   \n",
      "4559   0   0      0   0  2   0    0      0     0   0  ...       NaN       NaN   \n",
      "4560   0   0      0   0  0   0    0      0     0   0  ... -0.285357 -1.797079   \n",
      "4561   0   0      0   0  2   0    0      0     0   0  ... -0.285357       NaN   \n",
      "4562   0   0      0   0  3   0    0      0     0   0  ... -0.285357 -0.244334   \n",
      "4563   0   0      0   0  1   0    0      0     0   0  ... -0.285357 -1.301055   \n",
      "\n",
      "      Psi_i_1d       SdO     TI2_L      nCrt   SpMax_B   Psi_i_A     SM6_B  \\\n",
      "0     0.116323 -0.960603  0.573379 -0.097732 -1.096620 -1.694906 -0.981633   \n",
      "1    -1.254320       NaN -0.602971 -0.097732 -0.474730 -1.083778 -0.977175   \n",
      "2    -0.004804 -0.960603  0.733844 -0.097732       NaN -0.352374 -0.593796   \n",
      "3     6.886659 -0.110693 -0.686397 -0.097732       NaN  3.845886 -1.609081   \n",
      "4     0.033447  0.091289  1.012065 -0.097732 -0.413560 -0.371878 -0.145778   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "4559  2.192375  0.014197 -0.576829 -0.097732 -0.333051  0.987055 -0.810285   \n",
      "4560 -0.122743 -0.960603 -0.575417 -0.097732 -0.280775  0.138981 -0.693530   \n",
      "4561 -0.335619  0.069568  0.051879       NaN -0.412428  0.155474 -0.484217   \n",
      "4562 -0.245804       NaN -0.062540 -0.097732       NaN  0.691418 -0.250759   \n",
      "4563 -0.246285 -0.960603 -0.394644       NaN -0.955210 -0.033225 -1.415928   \n",
      "\n",
      "            nX  \n",
      "0    -0.147826  \n",
      "1    -0.147826  \n",
      "2    -0.147826  \n",
      "3    -0.147826  \n",
      "4          NaN  \n",
      "...        ...  \n",
      "4559 -0.147826  \n",
      "4560 -0.147826  \n",
      "4561 -0.147826  \n",
      "4562 -0.147826  \n",
      "4563 -0.147826  \n",
      "\n",
      "[4564 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "def cast_categorical_to_str(all_features: pd.DataFrame) -> pd.DataFrame:\n",
    "    is_categorical = lambda f: all_features[f].apply(lambda x: x.is_integer()).all()\n",
    "    categorical_cols = [f for f in all_features if is_categorical(f)]\n",
    "    other_cols = [f for f in all_features if not is_categorical(f)]\n",
    "    \n",
    "    categorical_matrix = all_features[categorical_cols].to_numpy().astype(int).astype(str)\n",
    "    headers = categorical_cols\n",
    "    \n",
    "    return pd.concat([all_features[other_cols], pd.DataFrame(data=categorical_matrix, columns=headers)], axis=1)\n",
    "\n",
    "\n",
    "def one_hot_encode_categorical_features(all_features: pd.DataFrame) -> pd.DataFrame:\n",
    "    is_categorical = lambda f: all_features[f].apply(lambda x: not isinstance(x, float) or x.is_integer()).all()\n",
    "    categorical_cols = [f for f in all_features if is_categorical(f)]\n",
    "    other_cols = [f for f in all_features if not is_categorical(f)]\n",
    "    \n",
    "    encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    categorical_matrix = all_features[categorical_cols].to_numpy().astype(int).astype(str)\n",
    "    categorical_encoded_matrix = encoder.fit_transform(categorical_matrix).toarray()\n",
    "    \n",
    "    headers = []\n",
    "    for base_name, categories in zip(categorical_cols, encoder.categories_):\n",
    "        for c in categories:\n",
    "            headers.append(base_name + \"_\" + c)\n",
    "        # print(f\"{base_name} has {len(categories)} categories\")\n",
    "    \n",
    "    return pd.concat([all_features[other_cols], pd.DataFrame(data=categorical_encoded_matrix, columns=headers)], axis=1)\n",
    "\n",
    "\n",
    "def scale_continuous_features(all_features: pd.DataFrame) -> pd.DataFrame:\n",
    "    is_continuous = lambda f: all_features[f].apply(lambda x: isinstance(x, float) and not x.is_integer()).any()\n",
    "    continuous_cols = [f for f in all_features if is_continuous(f)]\n",
    "    other_cols = [f for f in all_features if not is_continuous(f)]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    continuous = all_features[continuous_cols]\n",
    "    headers = continuous.columns\n",
    "    continuous_matrix = continuous.to_numpy()\n",
    "    continuous_scaled_matrix = scaler.fit_transform(continuous_matrix)\n",
    "    \n",
    "    return pd.concat([all_features[other_cols], pd.DataFrame(data=continuous_scaled_matrix, columns=headers)], axis=1)\n",
    "\n",
    "\n",
    "def preprocess(df: pd.DataFrame) -> (pd.DataFrame, np.ndarray):\n",
    "    #x = np.array(df.drop([\"Biodegradable\"], axis=1))\n",
    "    x = df.drop([\"Biodegradable\"], axis=1)\n",
    "    y = np.array(df[\"Biodegradable\"])\n",
    "    # x = one_hot_encode_categorical_features(x)\n",
    "    x = cast_categorical_to_str(x)\n",
    "    x = scale_continuous_features(x)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "x, y = preprocess(pd.read_csv(\"biodegradable_a.csv\"))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"nHM\": -1.4698770676520292,\n",
      "    \"F02_CN\": -0.861933098416884,\n",
      "    \"nCp\": -0.6995738774362152,\n",
      "    \"SpMax_L\": -0.6109924658101019,\n",
      "    \"nO\": 0.44481581054943864,\n",
      "    \"nCb\": -0.4009357409653489,\n",
      "    \"F01\": -0.32015282706975323,\n",
      "    \"nCrt\": -0.30827329489627764,\n",
      "    \"LOC\": 0.23797835132523126,\n",
      "    \"nX\": -0.18748864865426515,\n",
      "    \"F03\": -0.18691968931227684,\n",
      "    \"SpMax_B\": -0.1558834225542856,\n",
      "    \"Psi_i_A\": 0.017768339334521606,\n",
      "    \"F04\": 0.0,\n",
      "    \"NssssC\": 0.0,\n",
      "    \"nN_N\": 0.0,\n",
      "    \"nArNO2\": 0.0,\n",
      "    \"nCRX3\": 0.0,\n",
      "    \"B01\": 0.0,\n",
      "    \"B03\": 0.0,\n",
      "    \"N_073\": 0.0,\n",
      "    \"B04\": 0.0,\n",
      "    \"C_026\": 0.0,\n",
      "    \"nHDon\": 0.0,\n",
      "    \"nN\": 0.0,\n",
      "    \"nArCOOR\": 0.0,\n",
      "    \"J_Dz(e)\": 0.0,\n",
      "    \"C\": 0.0,\n",
      "    \"SdssC\": 0.0,\n",
      "    \"HyWi_B\": 0.0,\n",
      "    \"SM6_L\": 0.0,\n",
      "    \"F03_CO\": 0.0,\n",
      "    \"Me\": 0.0,\n",
      "    \"Mi\": 0.0,\n",
      "    \"SpPosA_B\": 0.0,\n",
      "    \"nCIR\": 0.0,\n",
      "    \"SpMax_A\": 0.0,\n",
      "    \"Psi_i_1d\": 0.0,\n",
      "    \"SdO\": 0.0,\n",
      "    \"TI2_L\": 0.0,\n",
      "    \"SM6_B\": 0.0\n",
      "}\n",
      "{\n",
      "    \"SpMax_B\": 0.07741662729863712,\n",
      "    \"SpMax_L\": 0.07649416653243214,\n",
      "    \"F02_CN\": 0.07334856580009046,\n",
      "    \"nHM\": 0.07131718732471247,\n",
      "    \"nX\": 0.06156119199539055,\n",
      "    \"F03\": 0.047193159706575324,\n",
      "    \"SpMax_A\": 0.03895007420610398,\n",
      "    \"SpPosA_B\": 0.03856814170404778,\n",
      "    \"F04\": 0.03344182425145394,\n",
      "    \"nCb\": 0.03209451397322116,\n",
      "    \"NssssC\": 0.03124487078158322,\n",
      "    \"SM6_B\": 0.02807040655236083,\n",
      "    \"Mi\": 0.02458890228971259,\n",
      "    \"nN\": 0.024572565299269686,\n",
      "    \"nCp\": 0.02317187400655639,\n",
      "    \"SM6_L\": 0.022901046321671992,\n",
      "    \"Psi_i_A\": 0.022714774324731825,\n",
      "    \"SdssC\": 0.02268913391341462,\n",
      "    \"LOC\": 0.021261844754892362,\n",
      "    \"J_Dz(e)\": 0.02116031262261705,\n",
      "    \"Me\": 0.020134615511413424,\n",
      "    \"C\": 0.01974208212673834,\n",
      "    \"TI2_L\": 0.0196743239894351,\n",
      "    \"HyWi_B\": 0.017366303851403524,\n",
      "    \"nCIR\": 0.01731958567463472,\n",
      "    \"C_026\": 0.016407479568375148,\n",
      "    \"SdO\": 0.01566114333564834,\n",
      "    \"B03\": 0.015582320411208541,\n",
      "    \"Psi_i_1d\": 0.013113031293381688,\n",
      "    \"nO\": 0.01278403847838277,\n",
      "    \"F03_CO\": 0.011457808908837479,\n",
      "    \"nArNO2\": 0.00926399264359957,\n",
      "    \"nHDon\": 0.006329206244300877,\n",
      "    \"nCrt\": 0.005280460352468964,\n",
      "    \"F01\": 0.003941590841166112,\n",
      "    \"B01\": 0.000978745584960464,\n",
      "    \"N_073\": 0.0008578173479068909,\n",
      "    \"nN_N\": 0.0007723015203003826,\n",
      "    \"nCRX3\": 0.00022087350787204115,\n",
      "    \"nArCOOR\": 0.0002193907393190977,\n",
      "    \"B04\": 0.00013170440917104105\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def rank_features_using_model(x: pd.DataFrame, y: np.ndarray, estimator) -> dict:\n",
    "    x = x.dropna()\n",
    "    y = y[x.index.values]\n",
    "    selector = SelectFromModel(estimator).fit(x.to_numpy(), y)\n",
    "    selected_columns = [col for col, was_selected in zip(x.columns, selector.get_feature_names_out(x.columns)) if was_selected]\n",
    "    selected_columns = selector.get_feature_names_out(x.columns)\n",
    "    x_selected = selector.transform(x.to_numpy())\n",
    "    \n",
    "    importances = selector.estimator_.coef_ if hasattr(selector.estimator_, \"coef_\") else selector.estimator_.feature_importances_\n",
    "    if len(importances) == 1:\n",
    "        importances = importances[0]\n",
    "    ranks = dict(sorted(zip(x.columns, importances), key=lambda r: abs(r[1]), reverse=True))\n",
    "    \n",
    "    return ranks\n",
    "\n",
    "\n",
    "def select_features_using_regularized_model(x: pd.DataFrame, y: np.ndarray) -> pd.DataFrame:\n",
    "    return select_features_using_model(x, y, LinearSVC(C=0.01, penalty=\"l1\", dual=False))\n",
    "    x = x.dropna()\n",
    "    y = y[x.index.values]\n",
    "    lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(x.to_numpy(), y)\n",
    "    model = SelectFromModel(lsvc, prefit=True)\n",
    "    headers = [col for col, was_selected in zip(x.columns, model.get_feature_names_out(x.columns)) if was_selected]\n",
    "    x_selected = model.transform(x.to_numpy())\n",
    "    return pd.DataFrame(data=x_selected, columns=headers)\n",
    "\n",
    "\n",
    "def select_features_using_random_forest(x: pd.DataFrame, y: np.ndarray) -> pd.DataFrame:\n",
    "    # return select_features_using_model(x, y, ExtraTreesClassifier(n_estimators=50))\n",
    "    x = x.dropna()\n",
    "    y = y[x.index.values]\n",
    "    clf = ExtraTreesClassifier(n_estimators=50)\n",
    "    clf = clf.fit(x.to_numpy(), y)\n",
    "    # print(clf.feature_importances_)\n",
    "    model = SelectFromModel(clf, prefit=True)\n",
    "    headers = [col for col, was_selected in zip(x.columns, model.get_feature_names_out(x.columns)) if was_selected]\n",
    "    x_selected = model.transform(x.to_numpy())\n",
    "    return pd.DataFrame(data=x_selected, columns=headers)\n",
    "    \n",
    "    \n",
    "x, y = preprocess(pd.read_csv(\"biodegradable_a.csv\"))\n",
    "features_ranked_with_svm = rank_features_using_model(x, y, LogisticRegression(C=0.1, penalty=\"l1\", solver=\"saga\", max_iter=1000))\n",
    "features_ranked_with_rf = rank_features_using_model(x, y, RandomForestClassifier(n_estimators=1000))\n",
    "\n",
    "import json\n",
    "print(json.dumps(features_ranked_with_svm, indent=4))\n",
    "print(json.dumps(features_ranked_with_rf, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     F02_CN   SpMax_L nHM F03  SpPosA_B F04 nCb NssssC     SM6_B nN        Mi  \\\n",
      "0         0 -1.320531   0   0  0.000615   0   0      0 -0.981633  0  0.328503   \n",
      "1         0 -0.798293   0   0 -1.207722   0   0      0 -0.977175  0  0.423761   \n",
      "2         0 -1.293482   0   0 -1.357207   0   0      0 -0.593796  0  0.804797   \n",
      "3         0 -3.232628   0   0 -2.204289   0   0      0 -1.609081  0  1.519239   \n",
      "4         0 -0.660971   0   0 -0.796638   0   0      0 -0.145778  0  0.566650   \n",
      "...     ...       ...  ..  ..       ...  ..  ..    ...       ... ..       ...   \n",
      "4559      0 -0.786537   0   0 -1.008886   0   0      0 -0.810285  0  0.726586   \n",
      "4560      0 -1.456332   0   0  0.976838   0   0      0 -0.693530  0  0.212358   \n",
      "4561      0 -0.538691   0   0 -0.926756   0   0      0 -0.484217  0  0.646039   \n",
      "4562      0  0.013934   0   0 -0.629899   0   0      0 -0.250759  0  0.342948   \n",
      "4563      2 -1.058169   0   0 -1.140085   0   0      0 -1.415928  1  1.322359   \n",
      "\n",
      "         SdssC  \n",
      "0     0.391883  \n",
      "1     0.391883  \n",
      "2     0.391883  \n",
      "3     0.391883  \n",
      "4     0.034488  \n",
      "...        ...  \n",
      "4559 -0.014714  \n",
      "4560  0.391883  \n",
      "4561  0.063353  \n",
      "4562  0.090427  \n",
      "4563  0.391883  \n",
      "\n",
      "[4564 rows x 12 columns]\n",
      "       SpMax_L  SpPosA_B     SM6_B        Mi     SdssC  F02_CN_0  F02_CN_1  \\\n",
      "0    -1.320531  0.000615 -0.981633  0.328503  0.391883       1.0       0.0   \n",
      "1    -0.798293 -1.207722 -0.977175  0.423761  0.391883       1.0       0.0   \n",
      "2    -1.293482 -1.357207 -0.593796  0.804797  0.391883       1.0       0.0   \n",
      "3    -3.232628 -2.204289 -1.609081  1.519239  0.391883       1.0       0.0   \n",
      "4    -0.660971 -0.796638 -0.145778  0.566650  0.034488       1.0       0.0   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "4559 -0.786537 -1.008886 -0.810285  0.726586 -0.014714       1.0       0.0   \n",
      "4560 -1.456332  0.976838 -0.693530  0.212358  0.391883       1.0       0.0   \n",
      "4561 -0.538691 -0.926756 -0.484217  0.646039  0.063353       1.0       0.0   \n",
      "4562  0.013934 -0.629899 -0.250759  0.342948  0.090427       1.0       0.0   \n",
      "4563 -1.058169 -1.140085 -1.415928  1.322359  0.391883       0.0       0.0   \n",
      "\n",
      "      F02_CN_10  F02_CN_13  F02_CN_14  ...  NssssC_8  NssssC_9  nN_0  nN_1  \\\n",
      "0           0.0        0.0        0.0  ...       0.0       0.0   1.0   0.0   \n",
      "1           0.0        0.0        0.0  ...       0.0       0.0   1.0   0.0   \n",
      "2           0.0        0.0        0.0  ...       0.0       0.0   1.0   0.0   \n",
      "3           0.0        0.0        0.0  ...       0.0       0.0   1.0   0.0   \n",
      "4           0.0        0.0        0.0  ...       0.0       0.0   1.0   0.0   \n",
      "...         ...        ...        ...  ...       ...       ...   ...   ...   \n",
      "4559        0.0        0.0        0.0  ...       0.0       0.0   1.0   0.0   \n",
      "4560        0.0        0.0        0.0  ...       0.0       0.0   1.0   0.0   \n",
      "4561        0.0        0.0        0.0  ...       0.0       0.0   1.0   0.0   \n",
      "4562        0.0        0.0        0.0  ...       0.0       0.0   1.0   0.0   \n",
      "4563        0.0        0.0        0.0  ...       0.0       0.0   0.0   1.0   \n",
      "\n",
      "      nN_2  nN_3  nN_4  nN_5  nN_6  nN_8  \n",
      "0      0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1      0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2      0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3      0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4      0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "...    ...   ...   ...   ...   ...   ...  \n",
      "4559   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4560   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4561   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4562   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4563   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[4564 rows x 105 columns]\n",
      "{'tree-gini-best-5': {'model': DecisionTreeClassifier(max_depth=5), 'evaluation': {'accuracy': 0.9947414548641542}}, 'tree-gini-best-10': {'model': DecisionTreeClassifier(max_depth=10), 'evaluation': {'accuracy': 0.9894829097283085}}, 'tree-gini-best-20': {'model': DecisionTreeClassifier(max_depth=20), 'evaluation': {'accuracy': 0.9842243645924628}}, 'tree-gini-best-50': {'model': DecisionTreeClassifier(max_depth=50), 'evaluation': {'accuracy': 0.9798422436459246}}, 'tree-gini-best-None': {'model': DecisionTreeClassifier(), 'evaluation': {'accuracy': 0.9833479404031551}}, 'logistic': {'model': LogisticRegression(max_iter=1000), 'evaluation': {'accuracy': 0.9973707274320771}}, 'randforest': {'model': RandomForestClassifier(), 'evaluation': {'accuracy': 1.0}}, 'linearsvc': {'model': LinearSVC(max_iter=10000), 'evaluation': {'accuracy': 0.9991235758106923}}, 'adaboost': {'model': AdaBoostClassifier(), 'evaluation': {'accuracy': 0.9912357581069238}}}\n"
     ]
    }
   ],
   "source": [
    "def simple_cross_validation(*, model, x, y, train_partition=(0, 0.75), metrics={\"accuracy\": accuracy_score}):\n",
    "    n, m = x.shape\n",
    "    \n",
    "    start = int(train_partition[0] * n)\n",
    "    end = int(train_partition[1] * n)\n",
    "    \n",
    "    x_train = x[start:end, :]\n",
    "    y_train = y[start:end]\n",
    "    x_test = np.concatenate((x[:start, :], x[end:, :]))\n",
    "    y_test = np.concatenate((y[:start], y[end:]))\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    return {metric_name: metric_f(y_test, y_pred) for (metric_name, metric_f) in metrics.items()}\n",
    "\n",
    "\n",
    "def tree_classifier(x: np.ndarray, y: np.ndarray, metrics, validation):\n",
    "    # Hyperparameters\n",
    "    criterions = [\"gini\"]\n",
    "    splitters = [\"best\"]\n",
    "    max_depths = [5, 10, 20, 50, None]\n",
    "    hyper_parameters = list(product(criterions, splitters, max_depths))\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for p in hyper_parameters:\n",
    "        criterion, splitter, max_depth = p\n",
    "        \n",
    "        model = tree.DecisionTreeClassifier(criterion=criterion,\n",
    "                                            splitter=splitter,\n",
    "                                            max_depth=max_depth)\n",
    "        model_results = validation(model, x, y, metrics)\n",
    "        model_name = \"tree-\" + \"-\".join([str(param) for param in p])\n",
    "        results[model_name] = {\"model\": model, \"evaluation\": model_results}\n",
    "        \n",
    "    return results\n",
    "\n",
    "\n",
    "def logistic_regression(x: np.ndarray, y: np.ndarray, metrics, validation):\n",
    "    results = {}\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model_results = validation(model, x, y, metrics)\n",
    "    results[\"logistic\"] = {\"model\": model, \"evaluation\": model_results}\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def linear_svc(x: np.ndarray, y: np.ndarray, metrics, validation):\n",
    "    results = {}\n",
    "\n",
    "    model = LinearSVC(max_iter=10000)\n",
    "    model_results = validation(model, x, y, metrics)\n",
    "    results[\"linearsvc\"] = {\"model\": model, \"evaluation\": model_results}\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def random_forest(x: np.ndarray, y: np.ndarray, metrics, validation):\n",
    "    results = {}\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "    model_results = validation(model, x, y, metrics)\n",
    "    results[\"randforest\"] = {\"model\": model, \"evaluation\": model_results}\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def adaboost(x: np.ndarray, y: np.ndarray, metrics, validation):\n",
    "    results = {}\n",
    "\n",
    "    model = AdaBoostClassifier()\n",
    "    model_results = validation(model, x, y, metrics)\n",
    "    results[\"adaboost\"] = {\"model\": model, \"evaluation\": model_results}\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def model_selection(x: np.ndarray, y: np.ndarray):\n",
    "    metrics = {\"accuracy\": accuracy_score}\n",
    "    validation = lambda model, x, y, _metrics: simple_cross_validation(model=model, x=x, y=y)\n",
    "    \n",
    "    results = {}\n",
    "    results |= tree_classifier(x, y, metrics, validation)\n",
    "    results |= logistic_regression(x, y, metrics, validation)\n",
    "    results |= random_forest(x, y, metrics, validation)\n",
    "    results |= linear_svc(x, y, metrics, validation)\n",
    "    results |= adaboost(x, y, metrics, validation)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"biodegradable_a.csv\")\n",
    "x, y = preprocess(df)\n",
    "selected_features = ['F02_CN', 'SpMax_L', 'nHM', 'F03', 'SpPosA_B', 'F04', 'nCb', 'NssssC', 'SM6_B', 'nN', 'Mi', 'SdssC'] # list(select_features_using_regularized_model(x, y).columns)\n",
    "x = x[selected_features]\n",
    "print(x)\n",
    "x = one_hot_encode_categorical_features(x)\n",
    "print(x)\n",
    "import json\n",
    "print(model_selection(x.to_numpy(), y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "055142e5cf66ed8ee87e97d9d29944a505c8696ace08c4c3475747b47f85af0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
