{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB, CategoricalNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, normalize, OneHotEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix, accuracy_score\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "def printClassResults(truth, preds):\n",
    "    print(\"The Accuracy is: %7.4f\" % accuracy_score(truth, preds))\n",
    "    print(\"The Precision is: %7.4f\" % precision_score(truth, preds, pos_label='RB'))\n",
    "    print(\"The Recall is: %7.4f\" % recall_score(truth, preds, pos_label='RB'))\n",
    "    print(\"The F1 score is: %7.4f\" % f1_score(truth, preds, pos_label='RB'))\n",
    "    print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(truth, preds))\n",
    "    print()\n",
    "    print(\"This is the Confusion Matrix\")\n",
    "    print(pd.DataFrame(confusion_matrix(truth, preds)))\n",
    "\n",
    "def one_hot_encode_categorical_features(all_features: pd.DataFrame) -> pd.DataFrame:\n",
    "    is_categorical = lambda f: all_features[f].apply(lambda x: not isinstance(x, float) or x.is_integer()).all()\n",
    "    categorical_cols = [f for f in all_features if is_categorical(f)]\n",
    "    other_cols = [f for f in all_features if not is_categorical(f)]\n",
    "    \n",
    "    encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    categorical_matrix = all_features[categorical_cols].to_numpy().astype(int).astype(str)\n",
    "    categorical_encoded_matrix = encoder.fit_transform(categorical_matrix).toarray()\n",
    "    \n",
    "    headers = []\n",
    "    for base_name, categories in zip(categorical_cols, encoder.categories_):\n",
    "        for c in categories:\n",
    "            headers.append(base_name + \"_\" + c)\n",
    "        # print(f\"{base_name} has {len(categories)} categories\")\n",
    "    \n",
    "    return pd.concat([all_features[other_cols], pd.DataFrame(data=categorical_encoded_matrix, columns=headers)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "41\n",
      "     nHM F04 NssssC nCb nO F03 nN_N nArNO2 nCRX3 B01  ...       SpMax_A  \\\n",
      "0      0   0      0   2  2   0    0      0     0   0  ...  7.635193e-01   \n",
      "1      1   0      0   0  3   0    0      0     0   0  ... -4.481867e-02   \n",
      "2      0   0      0   2  2   0    0      0     0   0  ...  2.805893e-14   \n",
      "3      0   0      0   2  1   0    0      0     0   0  ...  6.022004e-01   \n",
      "4      0   0      0   0  0   0    0      0     0   0  ... -1.439928e+00   \n",
      "...   ..  ..    ...  .. ..  ..  ...    ...   ...  ..  ...           ...   \n",
      "4559   0   1      0   0  1   1    0      0     0   0  ...  2.805893e-14   \n",
      "4560   0   0      0   0  3   0    0      0     0   0  ... -6.781979e-01   \n",
      "4561   0   0      0   0  2   0    0      0     0   0  ...  1.261149e+00   \n",
      "4562   0   0      0   0  1   0    0      0     0   0  ... -8.396889e-01   \n",
      "4563   0   0      0   2  1   0    0      0     0   0  ...  2.624708e-01   \n",
      "\n",
      "      Psi_i_1d       SdO     TI2_L      nCrt   SpMax_B       Psi_i_A  \\\n",
      "0    -0.036040  0.083128 -0.584680 -0.100618  0.238243  2.500987e-01   \n",
      "1    -0.456402  1.084060 -0.169867 -0.100618  0.000000  3.805872e-15   \n",
      "2     0.156821  0.159556 -0.027209 -0.100618  0.106006  3.805872e-15   \n",
      "3    -0.106805 -0.983609 -0.757658 -0.100618  0.000000 -5.215966e-01   \n",
      "4     2.047832 -0.983609 -0.481798 -0.100618 -0.639572  6.946340e-02   \n",
      "...        ...       ...       ...       ...       ...           ...   \n",
      "4559  0.046197  0.120121  2.653844 -0.100618 -0.578582 -1.324588e+00   \n",
      "4560 -0.225453  0.075614 -0.083576 -0.100618 -0.346790  8.524926e-01   \n",
      "4561  0.046197  0.238106  2.790161 -0.100618 -0.197445 -5.752902e-01   \n",
      "4562  0.310610 -0.983609  0.158243 -0.100618  0.000000 -6.914044e-01   \n",
      "4563  0.345826 -0.983609 -0.770957 -0.100618  0.107317  3.805872e-15   \n",
      "\n",
      "         SM6_B            nX  Biodegradable  \n",
      "0     0.139808 -1.602862e-01             RB  \n",
      "1     1.289686  2.612766e-17             RB  \n",
      "2     0.321156 -1.602862e-01             RB  \n",
      "3    -0.044913 -1.602862e-01             RB  \n",
      "4    -0.955872 -1.602862e-01             RB  \n",
      "...        ...           ...            ...  \n",
      "4559  0.190793 -1.602862e-01            NRB  \n",
      "4560 -0.454077 -1.602862e-01             RB  \n",
      "4561  0.630875 -1.602862e-01             RB  \n",
      "4562 -0.948363  2.612766e-17             RB  \n",
      "4563 -0.145778 -1.602862e-01             RB  \n",
      "\n",
      "[4564 rows x 42 columns]\n",
      "(4564, 42)\n"
     ]
    }
   ],
   "source": [
    "initial_dataset = pd.read_csv(\"biodegradable_a.csv\").sample(frac=1).reset_index(drop=True)\n",
    "total_len, _ = initial_dataset.shape\n",
    "\n",
    "# NOTE - NO INDEPENDENT VALIDATION SET !!!\n",
    "\n",
    "\n",
    "class_cols = [col for col in initial_dataset.drop(\"Biodegradable\", axis=1) if initial_dataset[col].apply(lambda x: x % 1 == 0).all()]\n",
    "num_cols = [col for col in initial_dataset.drop(\"Biodegradable\", axis=1) if initial_dataset[col].apply(lambda x: x % 1 != 0).any()]\n",
    "\n",
    "print(len(class_cols) + len(num_cols))\n",
    "print(len(initial_dataset.drop(\"Biodegradable\", axis=1).columns))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "total_categorical_dataset = initial_dataset[class_cols]\n",
    "total_categorical_dataset = total_categorical_dataset.fillna(-1)\n",
    "total_categorical_dataset = total_categorical_dataset.astype(int).astype(object).astype(str)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "total_numerical_dataset = initial_dataset[num_cols]\n",
    "total_numerical_dataset = total_numerical_dataset.fillna(total_numerical_dataset.mean())\n",
    "\n",
    "total_biodegradable = initial_dataset[\"Biodegradable\"]\n",
    "\n",
    "\n",
    "\n",
    "# Scale numerical data\n",
    "# https://scikit-learn.org/stable/modules/preproce\n",
    "#print(total_numerical_dataset)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# Commenting the following two lines will run the models without scaling. It allows the usage of certain Naive Bayes models, but ruins SVMs.\n",
    "# As the NaiveBayes that don't work with the negative numbers that come from the scaling of data, we keep it for the ones that show better results\n",
    "total_numerical_dataset = pd.DataFrame(scaler.fit_transform(total_numerical_dataset),\n",
    "             columns=total_numerical_dataset.columns, index=total_numerical_dataset.index)\n",
    "\n",
    "\n",
    "#total_numerical_dataset = pd.DataFrame(normalize(total_numerical_dataset, norm='l2', axis=1, copy=True, return_norm=False),\n",
    "#             columns=total_numerical_dataset.columns, index=total_numerical_dataset.index)\n",
    "\n",
    "#print(total_numerical_dataset)\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "total_dataset = pd.concat([total_categorical_dataset, total_numerical_dataset,total_biodegradable], axis=1)\n",
    "print(total_dataset)\n",
    "\n",
    "total_len, _ = total_dataset.shape\n",
    "train_dataset_len = round(total_len * 0.75)\n",
    "\n",
    "dataset_train = total_dataset[0:train_dataset_len]\n",
    "dataset_test = total_dataset[train_dataset_len:total_len]\n",
    "\n",
    "print(total_dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['nHM', 'F04', 'NssssC', 'nCb', 'nO', 'F03', 'nN_N', 'nArNO2', 'nCRX3',\n",
      "       'B01', 'B03', 'N_073', 'B04', 'C_026', 'F02_CN', 'nHDon', 'nN',\n",
      "       'nArCOOR', 'SpMax_L', 'J_Dz(e)', 'F01', 'C', 'nCp', 'SdssC', 'HyWi_B',\n",
      "       'LOC', 'SM6_L', 'F03_CO', 'Me', 'Mi', 'SpPosA_B', 'nCIR', 'SpMax_A',\n",
      "       'Psi_i_1d', 'SdO', 'TI2_L', 'nCrt', 'SpMax_B', 'Psi_i_A', 'SM6_B', 'nX',\n",
      "       'Biodegradable'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(total_dataset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Model with replaced values when NaN, and discarding the dropped NaN values dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     nHM F04 NssssC nCb nO F03 nN_N nArNO2 nCRX3 B01  ...      nCIR  \\\n",
      "0      0   0      0   2  2   0    0      0     0   0  ...  0.117354   \n",
      "1      1   0      0   0  3   0    0      0     0   0  ... -0.302031   \n",
      "2      0   0      0   2  2   0    0      0     0   0  ...  0.536738   \n",
      "3      0   0      0   2  1   0    0      0     0   0  ...  0.117354   \n",
      "4      0   0      0   0  0   0    0      0     0   0  ... -0.302031   \n",
      "...   ..  ..    ...  .. ..  ..  ...    ...   ...  ..  ...       ...   \n",
      "3418   0   0      0   0  2   0    0      0     0   0  ... -0.302031   \n",
      "3419   0   0      0   2  2   0    0      0     0   0  ...  0.117354   \n",
      "3420   0   0      0   0  1   0    0      0     0   0  ... -0.302031   \n",
      "3421   0   0      0   0  2   0    0      0     0   0  ... -0.302031   \n",
      "3422   0   0      0   0  2   0    0      0     0   0  ... -0.302031   \n",
      "\n",
      "           SpMax_A  Psi_i_1d       SdO     TI2_L      nCrt   SpMax_B  \\\n",
      "0     7.635193e-01 -0.036040  0.083128 -0.584680 -0.100618  0.238243   \n",
      "1    -4.481867e-02 -0.456402  1.084060 -0.169867 -0.100618  0.000000   \n",
      "2     2.805893e-14  0.156821  0.159556 -0.027209 -0.100618  0.106006   \n",
      "3     6.022004e-01 -0.106805 -0.983609 -0.757658 -0.100618  0.000000   \n",
      "4    -1.439928e+00  2.047832 -0.983609 -0.481798 -0.100618 -0.639572   \n",
      "...            ...       ...       ...       ...       ...       ...   \n",
      "3418 -1.646051e+00  0.590609 -0.030898 -0.675984 -0.100618 -0.565504   \n",
      "3419  6.228061e-01  0.138396  0.088124 -0.535523 -0.100618  0.000000   \n",
      "3420 -6.379969e-01  0.384358 -0.983609 -0.155574 -0.100618 -1.104080   \n",
      "3421 -2.357405e-02  0.378499  1.055580 -0.249307 -0.100618  0.000000   \n",
      "3422 -2.834807e-01  0.559866  0.067613 -0.566726 -0.100618  0.000000   \n",
      "\n",
      "           Psi_i_A     SM6_B            nX  \n",
      "0     2.500987e-01  0.139808 -1.602862e-01  \n",
      "1     3.805872e-15  1.289686  2.612766e-17  \n",
      "2     3.805872e-15  0.321156 -1.602862e-01  \n",
      "3    -5.215966e-01 -0.044913 -1.602862e-01  \n",
      "4     6.946340e-02 -0.955872 -1.602862e-01  \n",
      "...            ...       ...           ...  \n",
      "3418  2.640763e+00 -0.992050 -1.602862e-01  \n",
      "3419  6.018873e-01  0.171440 -1.602862e-01  \n",
      "3420  3.805872e-15 -1.153264 -1.602862e-01  \n",
      "3421  3.805872e-15 -0.130313 -1.602862e-01  \n",
      "3422  6.037654e-01 -0.482184 -1.602862e-01  \n",
      "\n",
      "[3423 rows x 41 columns]\n",
      "0       RB\n",
      "1       RB\n",
      "2       RB\n",
      "3       RB\n",
      "4       RB\n",
      "        ..\n",
      "3418    RB\n",
      "3419    RB\n",
      "3420    RB\n",
      "3421    RB\n",
      "3422    RB\n",
      "Name: Biodegradable, Length: 3423, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_train_total = dataset_train.drop([\"Biodegradable\"], axis=1)\n",
    "y_train_total = dataset_train.Biodegradable\n",
    "print(X_train_total)\n",
    "print(y_train_total)\n",
    "\n",
    "X_test_total = dataset_test.drop([\"Biodegradable\"], axis=1)\n",
    "y_test_total = dataset_test.Biodegradable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Random Forests for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SelectFromModel(estimator=RandomForestClassifier(), max_features=12)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=RandomForestClassifier(), max_features=12)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(), max_features=12)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://towardsdatascience.com/feature-selection-using-random-forest-26d7b747597f\n",
    "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100), max_features=12) # when no max_features are specified, seems to vary between 12 and 15\n",
    "sel.fit(X_train_total, y_train_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True False  True False False False False False False\n",
      " False False  True False False False  True False False False False False\n",
      " False False  True False False False  True False False False False False\n",
      " False  True False  True  True]\n",
      "12\n",
      "Index(['nHM', 'F04', 'NssssC', 'nCb', 'F03', 'F02_CN', 'SpMax_L', 'SM6_L',\n",
      "       'SpPosA_B', 'SpMax_B', 'SM6_B', 'nX'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(sel.get_support())\n",
    "selected_feat= X_train_total.columns[(sel.get_support())]\n",
    "print(len(selected_feat))\n",
    "print(selected_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     nHM F04 NssssC nCb F03 F02_CN   SpMax_L     SM6_L  SpPosA_B   SpMax_B  \\\n",
      "0      0   0      0   2   0      0  0.502761  0.262102  0.467673  0.238243   \n",
      "1      1   0      0   0   0      4  1.064719  0.332217 -0.831613  0.000000   \n",
      "2      0   0      0   2   0      0  0.262057  0.323590  1.037564  0.106006   \n",
      "3      0   0      0   2   0      0  0.445841  0.220531  0.812120  0.000000   \n",
      "4      0   0      0   0   0      0 -0.971360 -1.241510  0.585408 -0.639572   \n",
      "...   ..  ..    ...  ..  ..    ...       ...       ...       ...       ...   \n",
      "3418   0   0      0   0   0      1 -0.917662 -1.298313 -1.879649 -0.565504   \n",
      "3419   0   0      0   2   0      0  0.479167  0.324590  0.349936  0.000000   \n",
      "3420   0   0      0   0   0      0 -0.515278 -0.679934 -0.416422 -1.104080   \n",
      "3421   0   0      0   0   0      0  0.285715  0.070415 -1.550311  0.000000   \n",
      "3422   0   0      0   0   0      0  0.102410 -0.399898 -0.285076  0.000000   \n",
      "\n",
      "         SM6_B            nX  \n",
      "0     0.139808 -1.602862e-01  \n",
      "1     1.289686  2.612766e-17  \n",
      "2     0.321156 -1.602862e-01  \n",
      "3    -0.044913 -1.602862e-01  \n",
      "4    -0.955872 -1.602862e-01  \n",
      "...        ...           ...  \n",
      "3418 -0.992050 -1.602862e-01  \n",
      "3419  0.171440 -1.602862e-01  \n",
      "3420 -1.153264 -1.602862e-01  \n",
      "3421 -0.130313 -1.602862e-01  \n",
      "3422 -0.482184 -1.602862e-01  \n",
      "\n",
      "[3423 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train_rf = X_train_total[X_train_total.columns[(sel.get_support())]]\n",
    "X_test_rf = X_test_total[X_test_total.columns[(sel.get_support())]]\n",
    "\n",
    "print(X_train_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pd.concat([X_train_rf,X_test_rf])\n",
    "_ = one_hot_encode_categorical_features(_)\n",
    "X_train_rf_ohe = _[0:train_dataset_len]\n",
    "X_test_rf_ohe = _[train_dataset_len:total_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is:  0.9641\n",
      "The Precision is:  0.9845\n",
      "The Recall is:  0.9735\n",
      "The F1 score is:  0.9790\n",
      "The Matthews correlation coefficient is:  0.8558\n",
      "\n",
      "This is the Confusion Matrix\n",
      "     0    1\n",
      "0  145   15\n",
      "1   26  955\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators = 100)\n",
    "rf_model.fit(X_train_rf_ohe, y_train_total)\n",
    "\n",
    "preds = rf_model.predict(X_test_rf_ohe)\n",
    "truths = y_test_total.to_numpy()\n",
    "\n",
    "printClassResults(preds,truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Decision Tree test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is:  0.9474\n",
      "The Precision is:  0.9794\n",
      "The Recall is:  0.9596\n",
      "The F1 score is:  0.9694\n",
      "The Matthews correlation coefficient is:  0.7852\n",
      "\n",
      "This is the Confusion Matrix\n",
      "     0    1\n",
      "0  131   20\n",
      "1   40  950\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "rf_model = DecisionTreeClassifier(max_depth=5)\n",
    "rf_model.fit(X_train_rf_ohe, y_train_total)\n",
    "\n",
    "preds = rf_model.predict(X_test_rf_ohe)\n",
    "truths = y_test_total.to_numpy()\n",
    "\n",
    "printClassResults(preds,truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Random Forest Model for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_model_type = \"\"\n",
    "best_model_hyperparams = None\n",
    "best_fitness = -99999\n",
    "tested_models = []\n",
    "def rf_optimization(X_train: pd.DataFrame, y_train: pd.DataFrame, X_test: pd.DataFrame, y_test: pd.DataFrame, target_classes: list = [\"F1\"]) -> Tuple[RandomForestClassifier, np.array]:\n",
    "    \n",
    "    assert \"F1\" in target_classes or \"Accuracy\" in target_classes or \"Precision\" in target_classes or \"Recall\" in target_classes or \"MatthewsCorrelation\" in target_classes\n",
    "\n",
    "    #n_estimators = [100]\n",
    "    #n_estimators = [110,120,130,150,200]\n",
    "    #n_estimators = [110,115,120,125,130]\n",
    "    n_estimators = [125,126,127,128,129,130]\n",
    "    #criterion = [\"gini\"]\n",
    "    criterion = [\"gini\",\"entropy\",\"log_loss\"]\n",
    "    max_depth = [None]\n",
    "    min_samples_split = [2]\n",
    "    min_samples_leaf = [1]\n",
    "    min_weight_fraction_leaf = [0]\n",
    "    #max_features = [\"sqrt\"]\n",
    "    max_features = [\"sqrt\",\"log2\",None]\n",
    "    max_leaf_nodes = [None]\n",
    "    min_impurity_decrease = [0]\n",
    "    #bootstrap = [True]\n",
    "    bootstrap = [True,False]\n",
    "    #oob_score = [False]\n",
    "    oob_score = [False,True]\n",
    "    n_jobs = [None]\n",
    "    random_state = [None]\n",
    "    verbose = [0]\n",
    "    #warm_start = [False]\n",
    "    warm_start = [False,True]\n",
    "    class_weight = [None]\n",
    "    ccp_alpha = [0]\n",
    "    max_samples = [None]\n",
    "\n",
    "    rf_hyperparams = itertools.product(\n",
    "                                        n_estimators,\n",
    "                                        criterion,\n",
    "                                        max_depth,\n",
    "                                        min_samples_split,\n",
    "                                        min_samples_leaf,\n",
    "                                        min_weight_fraction_leaf,\n",
    "                                        max_features,\n",
    "                                        max_leaf_nodes,\n",
    "                                        min_impurity_decrease,\n",
    "                                        bootstrap,\n",
    "                                        oob_score,\n",
    "                                        n_jobs,\n",
    "                                        random_state,\n",
    "                                        verbose,\n",
    "                                        warm_start,\n",
    "                                        class_weight,\n",
    "                                        ccp_alpha,\n",
    "                                        max_samples\n",
    "                                    )\n",
    "\n",
    "    best_fitness = -99999\n",
    "    best_model = None\n",
    "    best_hyper_params = None\n",
    "\n",
    "    for hyper_param in rf_hyperparams:\n",
    "\n",
    "        n_estimators,\\\n",
    "            criterion,\\\n",
    "            max_depth,\\\n",
    "            min_samples_split,\\\n",
    "            min_samples_leaf,\\\n",
    "            min_weight_fraction_leaf,\\\n",
    "            max_features,\\\n",
    "            max_leaf_nodes,\\\n",
    "            min_impurity_decrease,\\\n",
    "            bootstrap,\\\n",
    "            oob_score,\\\n",
    "            n_jobs,\\\n",
    "            random_state,\\\n",
    "            verbose,\\\n",
    "            warm_start,\\\n",
    "            class_weight,\\\n",
    "            ccp_alpha,\\\n",
    "            max_samples\\\n",
    "                = hyper_param\n",
    "\n",
    "        if oob_score and not bootstrap:\n",
    "            continue\n",
    "\n",
    "        model = RandomForestClassifier(\n",
    "                        n_estimators=n_estimators,\n",
    "                        criterion=criterion,\n",
    "                        max_depth=max_depth,\n",
    "                        min_samples_split=min_samples_split,\n",
    "                        min_samples_leaf=min_samples_leaf,\n",
    "                        min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                        max_features=max_features,\n",
    "                        max_leaf_nodes=max_leaf_nodes,\n",
    "                        min_impurity_decrease=min_impurity_decrease,\n",
    "                        bootstrap=bootstrap,\n",
    "                        oob_score=oob_score,\n",
    "                        n_jobs=n_jobs,\n",
    "                        random_state=random_state,\n",
    "                        verbose=verbose,\n",
    "                        warm_start=warm_start,\n",
    "                        class_weight=class_weight,\n",
    "                        ccp_alpha=ccp_alpha,\n",
    "                        max_samples=max_samples\n",
    "                    )\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        truths = y_test.to_numpy()\n",
    "\n",
    "        fitness = 0\n",
    "\n",
    "        for target_class in target_classes:\n",
    "            if target_class == \"F1\":\n",
    "                fitness += f1_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"Accuracy\":\n",
    "                fitness += accuracy_score(truths, preds)\n",
    "            elif target_class == \"Precision\":\n",
    "                fitness += precision_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"Recall\":\n",
    "                fitness += recall_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"MatthewsCorrelation\":\n",
    "                fitness += matthews_corrcoef(truths, preds)\n",
    "            else:\n",
    "                raise Exception(f\"Unkown Metric {target_class}\")\n",
    "        \n",
    "        fitness = fitness / len(target_classes)\n",
    "\n",
    "        if fitness > best_fitness:\n",
    "            best_model = model\n",
    "            best_fitness = fitness\n",
    "            best_hyper_params = hyper_param\n",
    "        elif fitness == best_fitness:\n",
    "            print(str(fitness) + \"---\" + str(hyper_param))\n",
    "\n",
    "    \n",
    "    print(f\"Max Fitness = {str(fitness)} using the mean of {str(target_classes)}\")\n",
    "\n",
    "    n_estimators,\\\n",
    "            criterion,\\\n",
    "            max_depth,\\\n",
    "            min_samples_split,\\\n",
    "            min_samples_leaf,\\\n",
    "            min_weight_fraction_leaf,\\\n",
    "            max_features,\\\n",
    "            max_leaf_nodes,\\\n",
    "            min_impurity_decrease,\\\n",
    "            bootstrap,\\\n",
    "            oob_score,\\\n",
    "            n_jobs,\\\n",
    "            random_state,\\\n",
    "            verbose,\\\n",
    "            warm_start,\\\n",
    "            class_weight,\\\n",
    "            ccp_alpha,\\\n",
    "            max_samples\\\n",
    "                = best_hyper_params\n",
    "\n",
    "    best_hyper_params_dict = {\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"criterion\": criterion,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"min_samples_split\": min_samples_split,\n",
    "        \"min_samples_leaf\": min_samples_leaf,\n",
    "        \"min_weight_fraction_leaf\": min_weight_fraction_leaf,\n",
    "        \"max_features\": max_features,\n",
    "        \"max_leaf_nodes\": max_leaf_nodes,\n",
    "        \"min_impurity_decrease\": min_impurity_decrease,\n",
    "        \"bootstrap\": bootstrap,\n",
    "        \"oob_score\": oob_score,\n",
    "        \"n_jobs\": n_jobs,\n",
    "        \"random_state\": random_state,\n",
    "        \"verbose\": verbose,\n",
    "        \"warm_start\": warm_start,\n",
    "        \"class_weight\": class_weight,\n",
    "        \"ccp_alpha\": ccp_alpha,\n",
    "        \"max_samples\": max_samples\n",
    "    }\n",
    "\n",
    "    print(f\"Best Hyperparams = {str(best_hyper_params_dict)}\")\n",
    "    return best_model, best_fitness, best_hyper_params_dict\n",
    "\n",
    "\n",
    "model, fitness, hyper_params_dict = rf_optimization(X_train_rf_ohe, y_train_total, X_test_rf_ohe, y_test_total, [\"F1\", \"MatthewsCorrelation\",\"Accuracy\"])\n",
    "\n",
    "preds = model.predict(X_test_rf_ohe)\n",
    "truths = y_test_total.to_numpy()\n",
    "\n",
    "printClassResults(preds,truths)\n",
    "\n",
    "tested_models.append(\"RandomForestClassifier\")\n",
    "if fitness > best_fitness:\n",
    "    best_model = model\n",
    "    best_model_type = \"RandomForestClassifier\"\n",
    "    best_model_hyperparams = hyper_params_dict\n",
    "    best_fitness = fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is:  0.9553\n",
      "The Precision is:  0.9907\n",
      "The Recall is:  0.9581\n",
      "The F1 score is:  0.9742\n",
      "The Matthews correlation coefficient is:  0.8157\n",
      "\n",
      "This is the Confusion Matrix\n",
      "     0    1\n",
      "0  129    9\n",
      "1   42  961\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC()\n",
    "svc_model.fit(X_train_rf_ohe, y_train_total)\n",
    "\n",
    "preds = svc_model.predict(X_test_rf_ohe)\n",
    "truths = y_test_total.to_numpy()\n",
    "\n",
    "printClassResults(preds,truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Support Vector Machines for Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8903659194114709---(0.5, 'linear', 3, 'scale', 0, True, False, 0.001, 200, None, False, -1, 'ovo', False, None)\n",
      "0.8903659194114709---(0.5, 'linear', 3, 'scale', 0, True, True, 0.001, 200, None, False, -1, 'ovr', False, None)\n",
      "0.8903659194114709---(0.5, 'linear', 3, 'scale', 0, True, True, 0.001, 200, None, False, -1, 'ovo', False, None)\n",
      "0.8903659194114709---(0.5, 'linear', 3, 'scale', 0, False, False, 0.001, 200, None, False, -1, 'ovr', False, None)\n",
      "0.8903659194114709---(0.5, 'linear', 3, 'scale', 0, False, False, 0.001, 200, None, False, -1, 'ovo', False, None)\n",
      "0.8903659194114709---(0.5, 'linear', 3, 'scale', 0, False, True, 0.001, 200, None, False, -1, 'ovr', False, None)\n",
      "0.8903659194114709---(0.5, 'linear', 3, 'scale', 0, False, True, 0.001, 200, None, False, -1, 'ovo', False, None)\n",
      "0.9062429057641039---(0.5, 'poly', 3, 'scale', 0, True, False, 0.001, 200, None, False, -1, 'ovo', False, None)\n",
      "0.9062429057641039---(0.5, 'poly', 3, 'scale', 0, True, True, 0.001, 200, None, False, -1, 'ovr', False, None)\n",
      "0.9062429057641039---(0.5, 'poly', 3, 'scale', 0, True, True, 0.001, 200, None, False, -1, 'ovo', False, None)\n",
      "0.9062429057641039---(0.5, 'poly', 3, 'scale', 0, False, False, 0.001, 200, None, False, -1, 'ovr', False, None)\n",
      "0.9062429057641039---(0.5, 'poly', 3, 'scale', 0, False, False, 0.001, 200, None, False, -1, 'ovo', False, None)\n",
      "0.9062429057641039---(0.5, 'poly', 3, 'scale', 0, False, True, 0.001, 200, None, False, -1, 'ovr', False, None)\n",
      "0.9062429057641039---(0.5, 'poly', 3, 'scale', 0, False, True, 0.001, 200, None, False, -1, 'ovo', False, None)\n",
      "0.9149992655277419---(1, 'poly', 3, 'scale', 0, True, False, 0.001, 200, None, False, -1, 'ovo', False, None)\n",
      "0.9149992655277419---(1, 'poly', 3, 'scale', 0, True, True, 0.001, 200, None, False, -1, 'ovr', False, None)\n",
      "0.9149992655277419---(1, 'poly', 3, 'scale', 0, True, True, 0.001, 200, None, False, -1, 'ovo', False, None)\n",
      "0.9149992655277419---(1, 'poly', 3, 'scale', 0, False, False, 0.001, 200, None, False, -1, 'ovr', False, None)\n",
      "0.9149992655277419---(1, 'poly', 3, 'scale', 0, False, False, 0.001, 200, None, False, -1, 'ovo', False, None)\n",
      "0.9149992655277419---(1, 'poly', 3, 'scale', 0, False, True, 0.001, 200, None, False, -1, 'ovr', False, None)\n",
      "0.9149992655277419---(1, 'poly', 3, 'scale', 0, False, True, 0.001, 200, None, False, -1, 'ovo', False, None)\n",
      "0.9150401489373631---(1, 'rbf', 3, 'scale', 0, True, False, 0.001, 200, None, False, -1, 'ovo', False, None)\n",
      "0.9150401489373631---(1, 'rbf', 3, 'scale', 0, True, True, 0.001, 200, None, False, -1, 'ovr', False, None)\n",
      "0.9150401489373631---(1, 'rbf', 3, 'scale', 0, True, True, 0.001, 200, None, False, -1, 'ovo', False, None)\n",
      "0.9150401489373631---(1, 'rbf', 3, 'scale', 0, False, False, 0.001, 200, None, False, -1, 'ovr', False, None)\n",
      "0.9150401489373631---(1, 'rbf', 3, 'scale', 0, False, False, 0.001, 200, None, False, -1, 'ovo', False, None)\n",
      "0.9150401489373631---(1, 'rbf', 3, 'scale', 0, False, True, 0.001, 200, None, False, -1, 'ovr', False, None)\n",
      "0.9150401489373631---(1, 'rbf', 3, 'scale', 0, False, True, 0.001, 200, None, False, -1, 'ovo', False, None)\n",
      "0.917009038196465---(4, 'rbf', 3, 'scale', 0, True, False, 0.001, 200, None, False, -1, 'ovo', False, None)\n",
      "0.917009038196465---(4, 'rbf', 3, 'scale', 0, True, True, 0.001, 200, None, False, -1, 'ovr', False, None)\n",
      "0.917009038196465---(4, 'rbf', 3, 'scale', 0, True, True, 0.001, 200, None, False, -1, 'ovo', False, None)\n",
      "0.917009038196465---(4, 'rbf', 3, 'scale', 0, False, False, 0.001, 200, None, False, -1, 'ovr', False, None)\n",
      "0.917009038196465---(4, 'rbf', 3, 'scale', 0, False, False, 0.001, 200, None, False, -1, 'ovo', False, None)\n",
      "0.917009038196465---(4, 'rbf', 3, 'scale', 0, False, True, 0.001, 200, None, False, -1, 'ovr', False, None)\n",
      "0.917009038196465---(4, 'rbf', 3, 'scale', 0, False, True, 0.001, 200, None, False, -1, 'ovo', False, None)\n",
      "Max Fitness = 0.9068668495601885 using the mean of ['F1', 'MatthewsCorrelation', 'Accuracy']\n",
      "Best Hyperparams = {'C': 4, 'kernel': 'rbf', 'degree': 3, 'gamma': 'scale', 'coef0': 0, 'shrinking': True, 'probability': False, 'tol': False, 'cache_size': 200, 'class_weight': None, 'verbose': False, 'max_iter': -1, 'decision_function_shape': 'ovr', 'break_ties': False, 'random_state': None}\n",
      "The Accuracy is:  0.9562\n",
      "The Precision is:  0.9876\n",
      "The Recall is:  0.9618\n",
      "The F1 score is:  0.9746\n",
      "The Matthews correlation coefficient is:  0.8203\n",
      "\n",
      "This is the Confusion Matrix\n",
      "     0    1\n",
      "0  133   12\n",
      "1   38  958\n"
     ]
    }
   ],
   "source": [
    "def svc_optimization(X_train: pd.DataFrame, y_train: pd.DataFrame, X_test: pd.DataFrame, y_test: pd.DataFrame, target_classes: list = [\"F1\"]) -> Tuple[RandomForestClassifier, np.array]:\n",
    "    \n",
    "    assert \"F1\" in target_classes or \"Accuracy\" in target_classes or \"Precision\" in target_classes or \"Recall\" in target_classes or \"MatthewsCorrelation\" in target_classes\n",
    "\n",
    "    #C = [1]\n",
    "    C = [0.5,1,4,6,8,12]\n",
    "    #kernel = [\"rbf\"]\n",
    "    #kernel = ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed']\n",
    "    kernel = ['linear', 'poly', 'rbf']\n",
    "    degree = [3]\n",
    "    gamma = [\"scale\"]\n",
    "    coef0 = [0]\n",
    "    #shrinking = [True]\n",
    "    shrinking = [True,False]\n",
    "    #probability = [False]\n",
    "    probability = [False, True]\n",
    "    tol = [0.001]\n",
    "    cache_size = [200]\n",
    "    class_weight = [None]\n",
    "    verbose = [False]\n",
    "    max_iter = [-1]\n",
    "    #decision_function_shape = [\"ovr\"]\n",
    "    decision_function_shape = [\"ovr\", 'ovo']\n",
    "    break_ties = [False]\n",
    "    random_state = [None]\n",
    "\n",
    "    rf_hyperparams = itertools.product(\n",
    "                                        C,\\\n",
    "                                        kernel,\\\n",
    "                                        degree,\\\n",
    "                                        gamma,\\\n",
    "                                        coef0,\\\n",
    "                                        shrinking,\\\n",
    "                                        probability,\\\n",
    "                                        tol,\\\n",
    "                                        cache_size,\\\n",
    "                                        class_weight,\\\n",
    "                                        verbose,\\\n",
    "                                        max_iter,\\\n",
    "                                        decision_function_shape,\\\n",
    "                                        break_ties,\\\n",
    "                                        random_state\n",
    "                                    )\n",
    "\n",
    "    best_fitness = -99999\n",
    "    best_model = None\n",
    "    best_hyper_params = None\n",
    "\n",
    "    for hyper_param in rf_hyperparams:\n",
    "\n",
    "        C,\\\n",
    "            kernel,\\\n",
    "            degree,\\\n",
    "            gamma,\\\n",
    "            coef0,\\\n",
    "            shrinking,\\\n",
    "            probability,\\\n",
    "            tol,\\\n",
    "            cache_size,\\\n",
    "            class_weight,\\\n",
    "            verbose,\\\n",
    "            max_iter,\\\n",
    "            decision_function_shape,\\\n",
    "            break_ties,\\\n",
    "            random_state\\\n",
    "                = hyper_param\n",
    "\n",
    "        model = SVC(\n",
    "                        C=C,\\\n",
    "                        kernel=kernel,\\\n",
    "                        degree=degree,\\\n",
    "                        gamma=gamma,\\\n",
    "                        coef0=coef0,\\\n",
    "                        shrinking=shrinking,\\\n",
    "                        probability=probability,\\\n",
    "                        tol=tol,\\\n",
    "                        cache_size=cache_size,\\\n",
    "                        class_weight=class_weight,\\\n",
    "                        verbose=verbose,\\\n",
    "                        max_iter=max_iter,\\\n",
    "                        decision_function_shape=decision_function_shape,\\\n",
    "                        break_ties=break_ties,\\\n",
    "                        random_state=random_state\n",
    "                    )\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        truths = y_test.to_numpy()\n",
    "\n",
    "        fitness = 0\n",
    "\n",
    "        for target_class in target_classes:\n",
    "            if target_class == \"F1\":\n",
    "                fitness += f1_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"Accuracy\":\n",
    "                fitness += accuracy_score(truths, preds)\n",
    "            elif target_class == \"Precision\":\n",
    "                fitness += precision_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"Recall\":\n",
    "                fitness += recall_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"MatthewsCorrelation\":\n",
    "                fitness += matthews_corrcoef(truths, preds)\n",
    "            else:\n",
    "                raise Exception(f\"Unkown Metric {target_class}\")\n",
    "        \n",
    "        fitness = fitness / len(target_classes)\n",
    "\n",
    "        if fitness > best_fitness:\n",
    "            best_model = model\n",
    "            best_fitness = fitness\n",
    "            best_hyper_params = hyper_param\n",
    "        elif fitness == best_fitness:\n",
    "            print(str(fitness) + \"---\" + str(hyper_param))\n",
    "\n",
    "    \n",
    "    print(f\"Max Fitness = {str(fitness)} using the mean of {str(target_classes)}\")\n",
    "\n",
    "    C,\\\n",
    "        kernel,\\\n",
    "        degree,\\\n",
    "        gamma,\\\n",
    "        coef0,\\\n",
    "        shrinking,\\\n",
    "        probability,\\\n",
    "        tol,\\\n",
    "        cache_size,\\\n",
    "        class_weight,\\\n",
    "        verbose,\\\n",
    "        max_iter,\\\n",
    "        decision_function_shape,\\\n",
    "        break_ties,\\\n",
    "        random_state\\\n",
    "                = best_hyper_params\n",
    "\n",
    "    best_hyper_params_dict = {\n",
    "        \"C\": C,\n",
    "        \"kernel\": kernel,\n",
    "        \"degree\": degree,\n",
    "        \"gamma\": gamma,\n",
    "        \"coef0\": coef0,\n",
    "        \"shrinking\": shrinking,\n",
    "        \"probability\": probability,\n",
    "        \"tol\": probability,\n",
    "        \"cache_size\": cache_size,\n",
    "        \"class_weight\": class_weight,\n",
    "        \"verbose\": verbose,\n",
    "        \"max_iter\": max_iter,\n",
    "        \"decision_function_shape\": decision_function_shape,\n",
    "        \"break_ties\": break_ties,\n",
    "        \"random_state\": random_state\n",
    "    }\n",
    "\n",
    "    print(f\"Best Hyperparams = {str(best_hyper_params_dict)}\")\n",
    "    return best_model, best_fitness, best_hyper_params_dict\n",
    "\n",
    "\n",
    "model, fitness, hyper_params_dict = svc_optimization(X_train_rf_ohe, y_train_total, X_test_rf_ohe, y_test_total, [\"F1\", \"MatthewsCorrelation\",\"Accuracy\"])\n",
    "\n",
    "preds = model.predict(X_test_rf_ohe)\n",
    "truths = y_test_total.to_numpy()\n",
    "\n",
    "printClassResults(preds,truths)\n",
    "\n",
    "tested_models.append(\"SVC\")\n",
    "if fitness > best_fitness:\n",
    "    best_model = model\n",
    "    best_model_type = \"SVC\"\n",
    "    best_model_hyperparams = hyper_params_dict\n",
    "    best_fitness = fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8956796108658015---('l2', 'squared_hinge', True, 1e-07, 0.5, 'ovr', True, 1, None, 0, None, 1500)\n",
      "0.8956796108658015---('l2', 'squared_hinge', True, 1e-07, 0.5, 'ovr', True, 1, None, 0, None, 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8956796108658015---('l2', 'squared_hinge', True, 1e-07, 0.5, 'ovr', True, 1, None, 0, None, 3000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8956796108658015---('l2', 'squared_hinge', True, 1e-07, 1, 'ovr', True, 1, None, 0, None, 1000)\n",
      "0.8956796108658015---('l2', 'squared_hinge', True, 1e-07, 1, 'ovr', True, 1, None, 0, None, 1500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8956796108658015---('l2', 'squared_hinge', True, 1e-07, 1, 'ovr', True, 1, None, 0, None, 2000)\n",
      "0.8956796108658015---('l2', 'squared_hinge', True, 1e-07, 1, 'ovr', True, 1, None, 0, None, 3000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8956796108658015---('l2', 'squared_hinge', True, 0.0001, 0.5, 'ovr', True, 1, None, 0, None, 1000)\n",
      "0.8956796108658015---('l2', 'squared_hinge', True, 0.0001, 0.5, 'ovr', True, 1, None, 0, None, 1500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8956796108658015---('l2', 'squared_hinge', True, 0.0001, 0.5, 'ovr', True, 1, None, 0, None, 2000)\n",
      "0.8956796108658015---('l2', 'squared_hinge', True, 0.0001, 0.5, 'ovr', True, 1, None, 0, None, 3000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8956796108658015---('l2', 'squared_hinge', True, 0.0001, 1, 'ovr', True, 1, None, 0, None, 1000)\n",
      "0.8956796108658015---('l2', 'squared_hinge', True, 0.0001, 1, 'ovr', True, 1, None, 0, None, 1500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8956796108658015---('l2', 'squared_hinge', True, 0.0001, 1, 'ovr', True, 1, None, 0, None, 2000)\n",
      "0.8956796108658015---('l2', 'squared_hinge', True, 0.0001, 1, 'ovr', True, 1, None, 0, None, 3000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8957271396569354---('l2', 'squared_hinge', True, 0.01, 12, 'ovr', True, 1, None, 0, None, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Fitness = 0.8867279862222794 using the mean of ['F1', 'MatthewsCorrelation', 'Accuracy']\n",
      "Best Hyperparams = {'penalty': 'l2', 'loss': 'squared_hinge', 'dual': True, 'tol': 0.1, 'C': 6, 'multi_class': 'ovr', 'fit_intercept': True, 'intercept_scaling': 1, 'class_weight': None, 'verbose': 0, 'random_state': None, 'max_iter': 1000}\n",
      "The Accuracy is:  0.9483\n",
      "The Precision is:  0.9887\n",
      "The Recall is:  0.9523\n",
      "The F1 score is:  0.9702\n",
      "The Matthews correlation coefficient is:  0.7849\n",
      "\n",
      "This is the Confusion Matrix\n",
      "     0    1\n",
      "0  123   11\n",
      "1   48  959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def lsvc_optimization(X_train: pd.DataFrame, y_train: pd.DataFrame, X_test: pd.DataFrame, y_test: pd.DataFrame, target_classes: list = [\"F1\"]) -> Tuple[RandomForestClassifier, np.array]:\n",
    "    \n",
    "    assert \"F1\" in target_classes or \"Accuracy\" in target_classes or \"Precision\" in target_classes or \"Recall\" in target_classes or \"MatthewsCorrelation\" in target_classes\n",
    "\n",
    "    penalty = [\"l2\"]\n",
    "    #loss=[\"squared_hinge\"]\n",
    "    loss=['hinge','squared_hinge']\n",
    "    #dual=[True]\n",
    "    dual=[True,False]\n",
    "    tol=[0.0000001,0.0001,0.01,0.1,0.5,1]\n",
    "    #C = [1]\n",
    "    C = [0.5,1,4,6,8,12]\n",
    "    #multi_class=[\"ovr\"]\n",
    "    multi_class=['ovr','crammer_singer']\n",
    "    fit_intercept=[True]\n",
    "    intercept_scaling=[1]\n",
    "    class_weight=[None]\n",
    "    verbose=[0]\n",
    "    random_state=[None]\n",
    "    max_iter=[1000,1500,2000,3000]\n",
    "\n",
    "    rf_hyperparams = itertools.product(\n",
    "                                        penalty,\n",
    "                                        loss,\n",
    "                                        dual,\n",
    "                                        tol,\n",
    "                                        C,\n",
    "                                        multi_class,\n",
    "                                        fit_intercept,\n",
    "                                        intercept_scaling,\n",
    "                                        class_weight,\n",
    "                                        verbose,\n",
    "                                        random_state,\n",
    "                                        max_iter\n",
    "                                    )\n",
    "\n",
    "    best_fitness = -99999\n",
    "    best_model = None\n",
    "    best_hyper_params = None\n",
    "\n",
    "    for hyper_param in rf_hyperparams:\n",
    "\n",
    "        penalty,\\\n",
    "        loss,\\\n",
    "        dual,\\\n",
    "        tol,\\\n",
    "        C,\\\n",
    "        multi_class,\\\n",
    "        fit_intercept,\\\n",
    "        intercept_scaling,\\\n",
    "        class_weight,\\\n",
    "        verbose,\\\n",
    "        random_state,\\\n",
    "        max_iter\\\n",
    "                = hyper_param\n",
    "\n",
    "        if penalty=='l2' and loss=='hinge':\n",
    "            continue\n",
    "\n",
    "        model = LinearSVC(\n",
    "                        penalty=penalty,\\\n",
    "                        loss=loss,\\\n",
    "                        dual=dual,\\\n",
    "                        tol=tol,\\\n",
    "                        C=C,\\\n",
    "                        multi_class=multi_class,\\\n",
    "                        fit_intercept=fit_intercept,\\\n",
    "                        intercept_scaling=intercept_scaling,\\\n",
    "                        class_weight=class_weight,\\\n",
    "                        verbose=verbose,\\\n",
    "                        random_state=random_state,\\\n",
    "                        max_iter=max_iter\n",
    "                    )\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        truths = y_test.to_numpy()\n",
    "\n",
    "        fitness = 0\n",
    "\n",
    "        for target_class in target_classes:\n",
    "            if target_class == \"F1\":\n",
    "                fitness += f1_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"Accuracy\":\n",
    "                fitness += accuracy_score(truths, preds)\n",
    "            elif target_class == \"Precision\":\n",
    "                fitness += precision_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"Recall\":\n",
    "                fitness += recall_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"MatthewsCorrelation\":\n",
    "                fitness += matthews_corrcoef(truths, preds)\n",
    "            else:\n",
    "                raise Exception(f\"Unkown Metric {target_class}\")\n",
    "        \n",
    "        fitness = fitness / len(target_classes)\n",
    "\n",
    "        if fitness > best_fitness:\n",
    "            best_model = model\n",
    "            best_fitness = fitness\n",
    "            best_hyper_params = hyper_param\n",
    "        elif fitness == best_fitness:\n",
    "            print(str(fitness) + \"---\" + str(hyper_param))\n",
    "\n",
    "    \n",
    "    print(f\"Max Fitness = {str(fitness)} using the mean of {str(target_classes)}\")\n",
    "\n",
    "    penalty,\\\n",
    "    loss,\\\n",
    "    dual,\\\n",
    "    tol,\\\n",
    "    C,\\\n",
    "    multi_class,\\\n",
    "    fit_intercept,\\\n",
    "    intercept_scaling,\\\n",
    "    class_weight,\\\n",
    "    verbose,\\\n",
    "    random_state,\\\n",
    "    max_iter\\\n",
    "         = best_hyper_params\n",
    "\n",
    "    best_hyper_params_dict = {\n",
    "        \"penalty\": penalty,\n",
    "        \"loss\": loss,\n",
    "        \"dual\": dual,\n",
    "        \"tol\": tol,\n",
    "        \"C\": C,\n",
    "        \"multi_class\": multi_class,\n",
    "        \"fit_intercept\": fit_intercept,\n",
    "        \"intercept_scaling\": intercept_scaling,\n",
    "        \"class_weight\": class_weight,\n",
    "        \"verbose\": verbose,\n",
    "        \"random_state\": random_state,\n",
    "        \"max_iter\": max_iter\n",
    "    }\n",
    "\n",
    "    print(f\"Best Hyperparams = {str(best_hyper_params_dict)}\")\n",
    "    return best_model, best_fitness, best_hyper_params_dict\n",
    "\n",
    "\n",
    "model, fitness, hyper_params_dict = lsvc_optimization(X_train_rf_ohe, y_train_total, X_test_rf_ohe, y_test_total, [\"F1\", \"MatthewsCorrelation\",\"Accuracy\"])\n",
    "\n",
    "preds = model.predict(X_test_rf_ohe)\n",
    "truths = y_test_total.to_numpy()\n",
    "\n",
    "printClassResults(preds,truths)\n",
    "\n",
    "tested_models.append(\"LinearSVC\")\n",
    "if fitness > best_fitness:\n",
    "    best_model = model\n",
    "    best_model_type = \"LinearSVC\"\n",
    "    best_model_hyperparams = hyper_params_dict\n",
    "    best_fitness = fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes\n",
      "The Accuracy is:  0.9273\n",
      "The Precision is:  0.9515\n",
      "The Recall is:  0.9625\n",
      "The F1 score is:  0.9570\n",
      "The Matthews correlation coefficient is:  0.7224\n",
      "\n",
      "This is the Confusion Matrix\n",
      "     0    1\n",
      "0  135   47\n",
      "1   36  923\n",
      "\n",
      "\n",
      "Bernoulli Naive Bayes\n",
      "The Accuracy is:  0.8861\n",
      "The Precision is:  0.9227\n",
      "The Recall is:  0.9421\n",
      "The F1 score is:  0.9323\n",
      "The Matthews correlation coefficient is:  0.5747\n",
      "\n",
      "This is the Confusion Matrix\n",
      "     0    1\n",
      "0  116   75\n",
      "1   55  895\n"
     ]
    }
   ],
   "source": [
    "scaled = True # To use the models that don't work with scaled (negative) values.\n",
    "\n",
    "nb_model = GaussianNB() # Likelihood of the features is assumed to be Gaussian\n",
    "nb_model.fit(X_train_rf, y_train_total)\n",
    "\n",
    "preds = nb_model.predict(X_test_rf)\n",
    "truths = y_test_total.to_numpy()\n",
    "\n",
    "print(\"Gaussian Naive Bayes\")\n",
    "printClassResults(preds,truths)\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "if not scaled:\n",
    "    nb_model = MultinomialNB() # For multinomially distributed data\n",
    "    nb_model.fit(X_train_rf, y_train_total)\n",
    "\n",
    "    preds = nb_model.predict(X_test_rf)\n",
    "    truths = y_test_total.to_numpy()\n",
    "\n",
    "    print(\"Multinomial Naive Bayes\")\n",
    "    printClassResults(preds,truths)\n",
    "\n",
    "\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "    # For imbalanced datasets - ours seems to be really imbalenced towards the category \"RB\", but doesn't work with the data scaling. Tested it without scaling, didn't surpass the Gaussian nor the Bernoulli, so we didn't further optimize this\n",
    "    nb_model = ComplementNB()\n",
    "    nb_model.fit(X_train_rf, y_train_total)\n",
    "\n",
    "    preds = nb_model.predict(X_test_rf)\n",
    "    truths = y_test_total.to_numpy()\n",
    "\n",
    "    print(\"Complement Naive Bayes\")\n",
    "    printClassResults(preds,truths)\n",
    "\n",
    "\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "nb_model = BernoulliNB() # Distributed according to multivariate Bernoulli distributions\n",
    "nb_model.fit(X_train_rf, y_train_total)\n",
    "\n",
    "preds = nb_model.predict(X_test_rf)\n",
    "truths = y_test_total.to_numpy()\n",
    "\n",
    "print(\"Bernoulli Naive Bayes\")\n",
    "printClassResults(preds,truths)\n",
    "\n",
    "\n",
    "\n",
    "if not scaled:\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "    nb_model = CategoricalNB() # For categorically distributed data\n",
    "    nb_model.fit(X_train_rf, y_train_total)\n",
    "    \n",
    "    preds = nb_model.predict(X_test_rf)\n",
    "    truths = y_test_total.to_numpy()\n",
    "    \n",
    "    print(\"Categorical Naive Bayes\")\n",
    "    printClassResults(preds,truths)\n",
    "\n",
    "\n",
    "\n",
    "# Out-of-core with the partial_fit function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8688715384788606---(None, 1e-20)\n",
      "0.8688715384788606---(None, 1e-10)\n",
      "0.8688715384788606---(None, 1e-09)\n",
      "0.8688715384788606---(None, 1e-08)\n",
      "0.8688715384788606---(None, 1e-07)\n",
      "0.8688715384788606---(None, 1e-06)\n",
      "Max Fitness = 0.8584548700270367 using the mean of ['F1', 'MatthewsCorrelation', 'Accuracy']\n",
      "Best Hyperparams = {'priors': None, 'var_smoothing': 0}\n",
      "The Accuracy is:  0.9273\n",
      "The Precision is:  0.9515\n",
      "The Recall is:  0.9625\n",
      "The F1 score is:  0.9570\n",
      "The Matthews correlation coefficient is:  0.7224\n",
      "\n",
      "This is the Confusion Matrix\n",
      "     0    1\n",
      "0  135   47\n",
      "1   36  923\n"
     ]
    }
   ],
   "source": [
    "def gnb_optimization(X_train: pd.DataFrame, y_train: pd.DataFrame, X_test: pd.DataFrame, y_test: pd.DataFrame, target_classes: list = [\"F1\"]) -> Tuple[RandomForestClassifier, np.array]:\n",
    "    \n",
    "    assert \"F1\" in target_classes or \"Accuracy\" in target_classes or \"Precision\" in target_classes or \"Recall\" in target_classes or \"MatthewsCorrelation\" in target_classes\n",
    "\n",
    "    priors = [None]\n",
    "    #var_smoothing = [1e-9]\n",
    "    var_smoothing = [0,1e-20,1e-10,1e-9,1e-08,1e-07,1e-06,1e-02]\n",
    "\n",
    "    rf_hyperparams = itertools.product(\n",
    "                                        priors,\n",
    "                                        var_smoothing\n",
    "                                    )\n",
    "\n",
    "    best_fitness = -99999\n",
    "    best_model = None\n",
    "    best_hyper_params = None\n",
    "\n",
    "    for hyper_param in rf_hyperparams:\n",
    "\n",
    "        priors,\\\n",
    "        var_smoothing\\\n",
    "                = hyper_param\n",
    "\n",
    "        model = GaussianNB(\n",
    "                        priors=priors,\n",
    "                        var_smoothing=var_smoothing\n",
    "                    )\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        truths = y_test.to_numpy()\n",
    "\n",
    "        fitness = 0\n",
    "\n",
    "        for target_class in target_classes:\n",
    "            if target_class == \"F1\":\n",
    "                fitness += f1_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"Accuracy\":\n",
    "                fitness += accuracy_score(truths, preds)\n",
    "            elif target_class == \"Precision\":\n",
    "                fitness += precision_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"Recall\":\n",
    "                fitness += recall_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"MatthewsCorrelation\":\n",
    "                fitness += matthews_corrcoef(truths, preds)\n",
    "            else:\n",
    "                raise Exception(f\"Unkown Metric {target_class}\")\n",
    "        \n",
    "        fitness = fitness / len(target_classes)\n",
    "\n",
    "        if fitness > best_fitness:\n",
    "            best_model = model\n",
    "            best_fitness = fitness\n",
    "            best_hyper_params = hyper_param\n",
    "        elif fitness == best_fitness:\n",
    "            print(str(fitness) + \"---\" + str(hyper_param))\n",
    "\n",
    "    \n",
    "    print(f\"Max Fitness = {str(fitness)} using the mean of {str(target_classes)}\")\n",
    "\n",
    "    priors,\\\n",
    "    var_smoothing,\\\n",
    "                = best_hyper_params\n",
    "\n",
    "    best_hyper_params_dict = {\n",
    "        \"priors\": priors,\n",
    "        \"var_smoothing\": var_smoothing\n",
    "    }\n",
    "\n",
    "    print(f\"Best Hyperparams = {str(best_hyper_params_dict)}\")\n",
    "    return best_model, best_fitness, best_hyper_params_dict\n",
    "\n",
    "\n",
    "model, fitness, hyper_params_dict = gnb_optimization(X_train_rf_ohe, y_train_total, X_test_rf_ohe, y_test_total, [\"F1\", \"MatthewsCorrelation\",\"Accuracy\"])\n",
    "\n",
    "preds = model.predict(X_test_rf_ohe)\n",
    "truths = y_test_total.to_numpy()\n",
    "\n",
    "printClassResults(preds,truths)\n",
    "\n",
    "tested_models.append(\"GaussianNB\")\n",
    "if fitness > best_fitness:\n",
    "    best_model = model\n",
    "    best_model_type = \"GaussianNB\"\n",
    "    best_model_hyperparams = hyper_params_dict\n",
    "    best_fitness = fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8386694437070922---(1e-09, 1.75, True, None)\n",
      "0.8386694437070922---(1e-08, 1.75, True, None)\n",
      "0.8386694437070922---(1e-07, 1.75, True, None)\n",
      "0.8386694437070922---(1e-06, 1.75, True, None)\n",
      "0.8386694437070922---(1e-05, 1.75, True, None)\n",
      "0.8386694437070922---(0.0001, 1.75, True, None)\n",
      "0.8386694437070922---(0.001, 1.75, True, None)\n",
      "0.8386694437070922---(0.01, 1.75, True, None)\n",
      "0.8386694437070922---(0.1, 1.75, True, None)\n",
      "Max Fitness = 0.7547517624469914 using the mean of ['F1', 'MatthewsCorrelation', 'Accuracy']\n",
      "Best Hyperparams = {'alpha': 1e-10, 'binarize': 1.75, 'fit_prior': True, 'class_prior': None}\n",
      "The Accuracy is:  0.9150\n",
      "The Precision is:  0.9608\n",
      "The Recall is:  0.9405\n",
      "The F1 score is:  0.9505\n",
      "The Matthews correlation coefficient is:  0.6505\n",
      "\n",
      "This is the Confusion Matrix\n",
      "     0    1\n",
      "0  112   38\n",
      "1   59  932\n"
     ]
    }
   ],
   "source": [
    "def bnb_optimization(X_train: pd.DataFrame, y_train: pd.DataFrame, X_test: pd.DataFrame, y_test: pd.DataFrame, target_classes: list = [\"F1\"]) -> Tuple[RandomForestClassifier, np.array]:\n",
    "    \n",
    "    assert \"F1\" in target_classes or \"Accuracy\" in target_classes or \"Precision\" in target_classes or \"Recall\" in target_classes or \"MatthewsCorrelation\" in target_classes\n",
    "\n",
    "    #alpha = [1.0]\n",
    "    #alpha = [0,0.1,0.5,1.0,1.5,2]\n",
    "    alpha = [1e-10,1e-9,1e-8,1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,0.1]\n",
    "    #binarize = [0.0]\n",
    "    #binarize = [None,0.0,0.1,0.5,1,2]\n",
    "    binarize = [1,1.5,1.75,2,2.25,2.5,2.75,3,4]\n",
    "    fit_prior = [True]\n",
    "    #fit_prior = [True,False]\n",
    "    class_prior = [None]\n",
    "\n",
    "    rf_hyperparams = itertools.product(\n",
    "                                        alpha,\n",
    "                                        binarize,\n",
    "                                        fit_prior,\n",
    "                                        class_prior\n",
    "                                    )\n",
    "\n",
    "    best_fitness = -99999\n",
    "    best_model = None\n",
    "    best_hyper_params = None\n",
    "\n",
    "    for hyper_param in rf_hyperparams:\n",
    "\n",
    "        alpha,\\\n",
    "            binarize,\\\n",
    "            fit_prior,\\\n",
    "            class_prior\\\n",
    "                = hyper_param\n",
    "\n",
    "        model = BernoulliNB(\n",
    "                        alpha=alpha,\n",
    "                        binarize=binarize,\n",
    "                        fit_prior=fit_prior,\n",
    "                        class_prior=class_prior\n",
    "                    )\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        truths = y_test.to_numpy()\n",
    "\n",
    "        fitness = 0\n",
    "\n",
    "        for target_class in target_classes:\n",
    "            if target_class == \"F1\":\n",
    "                fitness += f1_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"Accuracy\":\n",
    "                fitness += accuracy_score(truths, preds)\n",
    "            elif target_class == \"Precision\":\n",
    "                fitness += precision_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"Recall\":\n",
    "                fitness += recall_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"MatthewsCorrelation\":\n",
    "                fitness += matthews_corrcoef(truths, preds)\n",
    "            else:\n",
    "                raise Exception(f\"Unkown Metric {target_class}\")\n",
    "        \n",
    "        fitness = fitness / len(target_classes)\n",
    "\n",
    "        if fitness > best_fitness:\n",
    "            best_model = model\n",
    "            best_fitness = fitness\n",
    "            best_hyper_params = hyper_param\n",
    "        elif fitness == best_fitness:\n",
    "            print(str(fitness) + \"---\" + str(hyper_param))\n",
    "\n",
    "    \n",
    "    print(f\"Max Fitness = {str(fitness)} using the mean of {str(target_classes)}\")\n",
    "\n",
    "    alpha,\\\n",
    "        binarize,\\\n",
    "        fit_prior,\\\n",
    "        class_prior\\\n",
    "                = best_hyper_params\n",
    "\n",
    "    best_hyper_params_dict = {\n",
    "        \"alpha\": alpha,\n",
    "        \"binarize\": binarize,\n",
    "        \"fit_prior\": fit_prior,\n",
    "        \"class_prior\": class_prior\n",
    "    }\n",
    "\n",
    "    print(f\"Best Hyperparams = {str(best_hyper_params_dict)}\")\n",
    "    return best_model, best_fitness, best_hyper_params_dict\n",
    "\n",
    "\n",
    "model, fitness, hyper_params_dict = bnb_optimization(X_train_rf, y_train_total, X_test_rf_ohe, y_test_total, [\"F1\", \"MatthewsCorrelation\",\"Accuracy\"])\n",
    "\n",
    "preds = model.predict(X_test_rf_ohe)\n",
    "truths = y_test_total.to_numpy()\n",
    "\n",
    "printClassResults(preds,truths)\n",
    "\n",
    "tested_models.append(\"BernoulliNB\")\n",
    "if fitness > best_fitness:\n",
    "    best_model = model\n",
    "    best_model_type = \"BernoulliNB\"\n",
    "    best_model_hyperparams = hyper_params_dict\n",
    "    best_fitness = fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Boosting\n",
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is:  0.9527\n",
      "The Precision is:  0.9856\n",
      "The Recall is:  0.9598\n",
      "The F1 score is:  0.9725\n",
      "The Matthews correlation coefficient is:  0.8055\n",
      "\n",
      "This is the Confusion Matrix\n",
      "     0    1\n",
      "0  131   14\n",
      "1   40  956\n"
     ]
    }
   ],
   "source": [
    "xgb_model = GradientBoostingClassifier()\n",
    "xgb_model.fit(X_train_rf, y_train_total)\n",
    "\n",
    "preds = xgb_model.predict(X_test_rf)\n",
    "truths = y_test_total.to_numpy()\n",
    "\n",
    "printClassResults(preds,truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9098574602081476---('log_loss', 0.1, 50, 1, 'squared_error', 2, 1, 0, 3, 0, None, None, None, 0, None, False, 0.1, None, 0.0001, 0)\n",
      "0.9240599613423942---('log_loss', 0.1, 200, 1, 'squared_error', 2, 1, 0, 3, 0, None, None, None, 0, None, False, 0.1, None, 0.0001, 0)\n",
      "0.9329478257365369---('exponential', 0.5, 1000, 1, 'friedman_mse', 2, 1, 0, 10, 0, None, None, None, 0, None, False, 0.1, None, 0.0001, 0)\n",
      "Max Fitness = 0.8788582651154259 using the mean of ['F1', 'MatthewsCorrelation', 'Accuracy']\n",
      "Best Hyperparams = {'loss': 'exponential', 'learning_rate': 0.2, 'n_estimators': 1000, 'subsample': 1, 'criterion': 'friedman_mse', 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_depth': 10, 'min_impurity_decrease': 0, 'init': None, 'random_state': None, 'max_features': None, 'verbose': 0, 'max_leaf_nodes': None, 'warm_start': False, 'validation_fraction': 0.1, 'n_iter_no_change': None, 'tol': 0.0001, 'ccp_alpha': 0}\n",
      "The Accuracy is:  0.9641\n",
      "The Precision is:  0.9845\n",
      "The Recall is:  0.9735\n",
      "The F1 score is:  0.9790\n",
      "The Matthews correlation coefficient is:  0.8558\n",
      "\n",
      "This is the Confusion Matrix\n",
      "     0    1\n",
      "0  145   15\n",
      "1   26  955\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tested_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rapos\\OneDrive\\Desktop\\IT\\Dev\\Workspace\\ML_HomeAssignments\\HA2\\main.ipynb Cell 31\u001b[0m in \u001b[0;36m<cell line: 195>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/ML_HomeAssignments/HA2/main.ipynb#X41sZmlsZQ%3D%3D?line=190'>191</a>\u001b[0m truths \u001b[39m=\u001b[39m y_test_total\u001b[39m.\u001b[39mto_numpy()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/ML_HomeAssignments/HA2/main.ipynb#X41sZmlsZQ%3D%3D?line=192'>193</a>\u001b[0m printClassResults(preds,truths)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/ML_HomeAssignments/HA2/main.ipynb#X41sZmlsZQ%3D%3D?line=194'>195</a>\u001b[0m tested_models\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39mGradientBoostingClassifier\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/ML_HomeAssignments/HA2/main.ipynb#X41sZmlsZQ%3D%3D?line=195'>196</a>\u001b[0m \u001b[39mif\u001b[39;00m fitness \u001b[39m>\u001b[39m best_fitness:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/ML_HomeAssignments/HA2/main.ipynb#X41sZmlsZQ%3D%3D?line=196'>197</a>\u001b[0m     best_model \u001b[39m=\u001b[39m model\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tested_models' is not defined"
     ]
    }
   ],
   "source": [
    "def gb_optimization(X_train: pd.DataFrame, y_train: pd.DataFrame, X_test: pd.DataFrame, y_test: pd.DataFrame, target_classes: list = [\"F1\"]) -> Tuple[RandomForestClassifier, np.array]:\n",
    "    \n",
    "    assert \"F1\" in target_classes or \"Accuracy\" in target_classes or \"Precision\" in target_classes or \"Recall\" in target_classes or \"MatthewsCorrelation\" in target_classes\n",
    "\n",
    "    #loss=[\"log_loss\"]\n",
    "    loss=['log_loss','exponential']\n",
    "    #learning_rate=[0.1]\n",
    "    learning_rate=[0.1,0.2,0.5,1]\n",
    "    #n_estimators=[100]\n",
    "    n_estimators=[50,100,150,200,1000]\n",
    "    subsample=[1]\n",
    "    #criterion=[\"friedman_mse\"]\n",
    "    #criterion=['friedman_mse','squared_error','mse']\n",
    "    criterion=['friedman_mse','squared_error']\n",
    "    min_samples_split=[2]\n",
    "    min_samples_leaf=[1]\n",
    "    min_weight_fraction_leaf=[0]\n",
    "    #max_depth=[3]\n",
    "    max_depth=[2,3,10,30]\n",
    "    min_impurity_decrease=[0]\n",
    "    init=[None]\n",
    "    random_state=[None]\n",
    "    max_features=[None]\n",
    "    verbose=[0]\n",
    "    max_leaf_nodes=[None]\n",
    "    warm_start=[False]\n",
    "    validation_fraction=[0.1]\n",
    "    n_iter_no_change=[None]\n",
    "    tol=[0.0001]\n",
    "    ccp_alpha=[0]\n",
    "\n",
    "    rf_hyperparams = itertools.product(\n",
    "                                        loss,\n",
    "                                        learning_rate,\n",
    "                                        n_estimators,\n",
    "                                        subsample,\n",
    "                                        criterion,\n",
    "                                        min_samples_split,\n",
    "                                        min_samples_leaf,\n",
    "                                        min_weight_fraction_leaf,\n",
    "                                        max_depth,\n",
    "                                        min_impurity_decrease,\n",
    "                                        init,\n",
    "                                        random_state,\n",
    "                                        max_features,\n",
    "                                        verbose,\n",
    "                                        max_leaf_nodes,\n",
    "                                        warm_start,\n",
    "                                        validation_fraction,\n",
    "                                        n_iter_no_change,\n",
    "                                        tol,\n",
    "                                        ccp_alpha\n",
    "                                    )\n",
    "\n",
    "    best_fitness = -99999\n",
    "    best_model = None\n",
    "    best_hyper_params = None\n",
    "\n",
    "    for hyper_param in rf_hyperparams:\n",
    "\n",
    "        loss,\\\n",
    "        learning_rate,\\\n",
    "        n_estimators,\\\n",
    "        subsample,\\\n",
    "        criterion,\\\n",
    "        min_samples_split,\\\n",
    "        min_samples_leaf,\\\n",
    "        min_weight_fraction_leaf,\\\n",
    "        max_depth,\\\n",
    "        min_impurity_decrease,\\\n",
    "        init,\\\n",
    "        random_state,\\\n",
    "        max_features,\\\n",
    "        verbose,\\\n",
    "        max_leaf_nodes,\\\n",
    "        warm_start,\\\n",
    "        validation_fraction,\\\n",
    "        n_iter_no_change,\\\n",
    "        tol,\\\n",
    "        ccp_alpha\\\n",
    "             = hyper_param\n",
    "\n",
    "        model = GradientBoostingClassifier(\n",
    "                        loss=loss,\n",
    "                        learning_rate=learning_rate,\n",
    "                        n_estimators=n_estimators,\n",
    "                        subsample=subsample,\n",
    "                        criterion=criterion,\n",
    "                        min_samples_split=min_samples_split,\n",
    "                        min_samples_leaf=min_samples_leaf,\n",
    "                        min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                        max_depth=max_depth,\n",
    "                        min_impurity_decrease=min_impurity_decrease,\n",
    "                        init=init,\n",
    "                        random_state=random_state,\n",
    "                        max_features=max_features,\n",
    "                        verbose=verbose,\n",
    "                        max_leaf_nodes=max_leaf_nodes,\n",
    "                        warm_start=warm_start,\n",
    "                        validation_fraction=validation_fraction,\n",
    "                        n_iter_no_change=n_iter_no_change,\n",
    "                        tol=tol,\n",
    "                        ccp_alpha=ccp_alpha\n",
    "                    )\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        truths = y_test.to_numpy()\n",
    "\n",
    "        fitness = 0\n",
    "\n",
    "        for target_class in target_classes:\n",
    "            if target_class == \"F1\":\n",
    "                fitness += f1_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"Accuracy\":\n",
    "                fitness += accuracy_score(truths, preds)\n",
    "            elif target_class == \"Precision\":\n",
    "                fitness += precision_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"Recall\":\n",
    "                fitness += recall_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"MatthewsCorrelation\":\n",
    "                fitness += matthews_corrcoef(truths, preds)\n",
    "            else:\n",
    "                raise Exception(f\"Unkown Metric {target_class}\")\n",
    "        \n",
    "        fitness = fitness / len(target_classes)\n",
    "\n",
    "        if fitness > best_fitness:\n",
    "            best_model = model\n",
    "            best_fitness = fitness\n",
    "            best_hyper_params = hyper_param\n",
    "        elif fitness == best_fitness:\n",
    "            print(str(fitness) + \"---\" + str(hyper_param))\n",
    "\n",
    "    \n",
    "    print(f\"Max Fitness = {str(fitness)} using the mean of {str(target_classes)}\")\n",
    "\n",
    "    loss,\\\n",
    "    learning_rate,\\\n",
    "    n_estimators,\\\n",
    "    subsample,\\\n",
    "    criterion,\\\n",
    "    min_samples_split,\\\n",
    "    min_samples_leaf,\\\n",
    "    min_weight_fraction_leaf,\\\n",
    "    max_depth,\\\n",
    "    min_impurity_decrease,\\\n",
    "    init,\\\n",
    "    random_state,\\\n",
    "    max_features,\\\n",
    "    verbose,\\\n",
    "    max_leaf_nodes,\\\n",
    "    warm_start,\\\n",
    "    validation_fraction,\\\n",
    "    n_iter_no_change,\\\n",
    "    tol,\\\n",
    "    ccp_alpha\\\n",
    "            = best_hyper_params\n",
    "\n",
    "    best_hyper_params_dict = {\n",
    "        \"loss\": loss,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"subsample\": subsample,\n",
    "        \"criterion\": criterion,\n",
    "        \"min_samples_split\": min_samples_split,\n",
    "        \"min_samples_leaf\": min_samples_leaf,\n",
    "        \"min_weight_fraction_leaf\": min_weight_fraction_leaf,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"min_impurity_decrease\": min_impurity_decrease,\n",
    "        \"init\": init,\n",
    "        \"random_state\": random_state,\n",
    "        \"max_features\": max_features,\n",
    "        \"verbose\": verbose,\n",
    "        \"max_leaf_nodes\": max_leaf_nodes,\n",
    "        \"warm_start\": warm_start,\n",
    "        \"validation_fraction\": validation_fraction,\n",
    "        \"n_iter_no_change\": n_iter_no_change,\n",
    "        \"tol\": tol,\n",
    "        \"ccp_alpha\": ccp_alpha\n",
    "    }\n",
    "\n",
    "    print(f\"Best Hyperparams = {str(best_hyper_params_dict)}\")\n",
    "    return best_model, best_fitness, best_hyper_params_dict\n",
    "\n",
    "\n",
    "model, fitness, hyper_params_dict = gb_optimization(X_train_rf_ohe, y_train_total, X_test_rf_ohe, y_test_total, [\"F1\", \"MatthewsCorrelation\",\"Accuracy\"])\n",
    "\n",
    "preds = model.predict(X_test_rf_ohe)\n",
    "truths = y_test_total.to_numpy()\n",
    "\n",
    "printClassResults(preds,truths)\n",
    "\n",
    "tested_models.append(\"GradientBoostingClassifier\")\n",
    "if fitness > best_fitness:\n",
    "    best_model = model\n",
    "    best_model_type = \"GradientBoostingClassifier\"\n",
    "    best_model_hyperparams = hyper_params_dict\n",
    "    best_fitness = fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is:  0.9430\n",
      "The Precision is:  0.9794\n",
      "The Recall is:  0.9548\n",
      "The F1 score is:  0.9669\n",
      "The Matthews correlation coefficient is:  0.7653\n",
      "\n",
      "This is the Confusion Matrix\n",
      "     0    1\n",
      "0  126   20\n",
      "1   45  950\n"
     ]
    }
   ],
   "source": [
    "adab_model = AdaBoostClassifier()\n",
    "adab_model.fit(X_train_rf, y_train_total)\n",
    "\n",
    "preds = adab_model.predict(X_test_rf)\n",
    "truths = y_test_total.to_numpy()\n",
    "\n",
    "printClassResults(preds,truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HistGradientBoost (Histogram-Based Gradient Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is:  0.9693\n",
      "The Precision is:  0.9866\n",
      "The Recall is:  0.9775\n",
      "The F1 score is:  0.9820\n",
      "The Matthews correlation coefficient is:  0.8774\n",
      "\n",
      "This is the Confusion Matrix\n",
      "     0    1\n",
      "0  149   13\n",
      "1   22  957\n"
     ]
    }
   ],
   "source": [
    "_y_train = initial_dataset[\"Biodegradable\"][0:train_dataset_len]\n",
    "_y_test = initial_dataset[\"Biodegradable\"][train_dataset_len:total_len]\n",
    "\n",
    "_X_train = initial_dataset.drop([\"Biodegradable\"], axis=1)[0:train_dataset_len]\n",
    "_X_test = initial_dataset.drop([\"Biodegradable\"], axis=1)[train_dataset_len:total_len]\n",
    "\n",
    "histb_model = HistGradientBoostingClassifier()\n",
    "histb_model.fit(_X_train, _y_train)\n",
    "\n",
    "preds = histb_model.predict(_X_test)\n",
    "truths = _y_test.to_numpy()\n",
    "\n",
    "printClassResults(preds,truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is:  0.9579\n",
      "The Precision is:  0.9897\n",
      "The Recall is:  0.9619\n",
      "The F1 score is:  0.9756\n",
      "The Matthews correlation coefficient is:  0.8274\n",
      "\n",
      "This is the Confusion Matrix\n",
      "     0    1\n",
      "0  133   10\n",
      "1   38  960\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train_rf, y_train_total)\n",
    "\n",
    "preds = knn_model.predict(X_test_rf)\n",
    "truths = y_test_total.to_numpy()\n",
    "\n",
    "printClassResults(preds,truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.923770497287316---(3, 'uniform', 'auto', 25, 1, 'minkowski', None, None)\n",
      "0.923770497287316---(3, 'uniform', 'auto', 30, 1, 'minkowski', None, None)\n",
      "0.923770497287316---(3, 'uniform', 'auto', 35, 1, 'minkowski', None, None)\n",
      "0.923770497287316---(3, 'uniform', 'auto', 40, 1, 'minkowski', None, None)\n",
      "0.923770497287316---(3, 'uniform', 'ball_tree', 20, 1, 'minkowski', None, None)\n",
      "0.923770497287316---(3, 'uniform', 'ball_tree', 25, 1, 'minkowski', None, None)\n",
      "0.923770497287316---(3, 'uniform', 'ball_tree', 30, 1, 'minkowski', None, None)\n",
      "0.923770497287316---(3, 'uniform', 'ball_tree', 35, 1, 'minkowski', None, None)\n",
      "0.923770497287316---(3, 'uniform', 'ball_tree', 40, 1, 'minkowski', None, None)\n",
      "0.923770497287316---(3, 'uniform', 'kd_tree', 20, 1, 'minkowski', None, None)\n",
      "0.923770497287316---(3, 'uniform', 'kd_tree', 25, 1, 'minkowski', None, None)\n",
      "0.923770497287316---(3, 'uniform', 'kd_tree', 30, 1, 'minkowski', None, None)\n",
      "0.923770497287316---(3, 'uniform', 'kd_tree', 35, 1, 'minkowski', None, None)\n",
      "0.923770497287316---(3, 'uniform', 'kd_tree', 40, 1, 'minkowski', None, None)\n",
      "0.923770497287316---(3, 'uniform', 'brute', 20, 1, 'minkowski', None, None)\n",
      "0.923770497287316---(3, 'uniform', 'brute', 25, 1, 'minkowski', None, None)\n",
      "0.923770497287316---(3, 'uniform', 'brute', 30, 1, 'minkowski', None, None)\n",
      "0.923770497287316---(3, 'uniform', 'brute', 35, 1, 'minkowski', None, None)\n",
      "0.923770497287316---(3, 'uniform', 'brute', 40, 1, 'minkowski', None, None)\n",
      "Max Fitness = 0.9062429057641039 using the mean of ['F1', 'MatthewsCorrelation', 'Accuracy']\n",
      "Best Hyperparams = {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 20, 'p': 1, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None}\n",
      "The Accuracy is:  0.9597\n",
      "The Precision is:  0.9897\n",
      "The Recall is:  0.9639\n",
      "The F1 score is:  0.9766\n",
      "The Matthews correlation coefficient is:  0.8350\n",
      "\n",
      "This is the Confusion Matrix\n",
      "     0    1\n",
      "0  135   10\n",
      "1   36  960\n"
     ]
    }
   ],
   "source": [
    "def knn_optimization(X_train: pd.DataFrame, y_train: pd.DataFrame, X_test: pd.DataFrame, y_test: pd.DataFrame, target_classes: list = [\"F1\"]) -> Tuple[RandomForestClassifier, np.array]:\n",
    "    \n",
    "    assert \"F1\" in target_classes or \"Accuracy\" in target_classes or \"Precision\" in target_classes or \"Recall\" in target_classes or \"MatthewsCorrelation\" in target_classes\n",
    "\n",
    "    #n_neighbors=[5]\n",
    "    n_neighbors=[3,4,5,6,7,8,10]\n",
    "    #weights=[\"uniform\"]\n",
    "    weights=['uniform','distance']\n",
    "    #algorithm=[\"auto\"]\n",
    "    algorithm=['auto','ball_tree','kd_tree','brute']\n",
    "    #leaf_size=[30]\n",
    "    leaf_size=[20,25,30,35,40]\n",
    "    #p=[2]\n",
    "    p=[1,2]\n",
    "    metric=[\"minkowski\"]\n",
    "    #metric=[\"minkowski\",\"precomputed\"]\n",
    "    metric_params=[None]\n",
    "    n_jobs=[None]\n",
    "\n",
    "    rf_hyperparams = itertools.product(\n",
    "                                        n_neighbors,\n",
    "                                        weights,\n",
    "                                        algorithm,\n",
    "                                        leaf_size,\n",
    "                                        p,\n",
    "                                        metric,\n",
    "                                        metric_params,\n",
    "                                        n_jobs\n",
    "                                    )\n",
    "\n",
    "    best_fitness = -99999\n",
    "    best_model = None\n",
    "    best_hyper_params = None\n",
    "\n",
    "    for hyper_param in rf_hyperparams:\n",
    "\n",
    "        n_neighbors,\\\n",
    "        weights,\\\n",
    "        algorithm,\\\n",
    "        leaf_size,\\\n",
    "        p,\\\n",
    "        metric,\\\n",
    "        metric_params,\\\n",
    "        n_jobs\\\n",
    "                = hyper_param\n",
    "\n",
    "        model = KNeighborsClassifier(\n",
    "                        n_neighbors=n_neighbors,\n",
    "                        weights=weights,\n",
    "                        algorithm=algorithm,\n",
    "                        leaf_size=leaf_size,\n",
    "                        p=p,\n",
    "                        metric=metric,\n",
    "                        metric_params=metric_params,\n",
    "                        n_jobs=n_jobs\n",
    "                    )\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        truths = y_test.to_numpy()\n",
    "\n",
    "        fitness = 0\n",
    "\n",
    "        for target_class in target_classes:\n",
    "            if target_class == \"F1\":\n",
    "                fitness += f1_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"Accuracy\":\n",
    "                fitness += accuracy_score(truths, preds)\n",
    "            elif target_class == \"Precision\":\n",
    "                fitness += precision_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"Recall\":\n",
    "                fitness += recall_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"MatthewsCorrelation\":\n",
    "                fitness += matthews_corrcoef(truths, preds)\n",
    "            else:\n",
    "                raise Exception(f\"Unkown Metric {target_class}\")\n",
    "        \n",
    "        fitness = fitness / len(target_classes)\n",
    "\n",
    "        if fitness > best_fitness:\n",
    "            best_model = model\n",
    "            best_fitness = fitness\n",
    "            best_hyper_params = hyper_param\n",
    "        elif fitness == best_fitness:\n",
    "            print(str(fitness) + \"---\" + str(hyper_param))\n",
    "\n",
    "    \n",
    "    print(f\"Max Fitness = {str(fitness)} using the mean of {str(target_classes)}\")\n",
    "\n",
    "    n_neighbors,\\\n",
    "    weights,\\\n",
    "    algorithm,\\\n",
    "    leaf_size,\\\n",
    "    p,\\\n",
    "    metric,\\\n",
    "    metric_params,\\\n",
    "    n_jobs\\\n",
    "         = best_hyper_params\n",
    "\n",
    "    best_hyper_params_dict = {\n",
    "        \"n_neighbors\": n_neighbors,\n",
    "        \"weights\": weights,\n",
    "        \"algorithm\": algorithm,\n",
    "        \"leaf_size\": leaf_size,\n",
    "        \"p\": p,\n",
    "        \"metric\": metric,\n",
    "        \"metric_params\": metric_params,\n",
    "        \"n_jobs\": n_jobs\n",
    "    }\n",
    "\n",
    "    print(f\"Best Hyperparams = {str(best_hyper_params_dict)}\")\n",
    "    return best_model, best_fitness, best_hyper_params_dict\n",
    "\n",
    "\n",
    "model, fitness, hyper_params_dict = knn_optimization(X_train_rf_ohe, y_train_total, X_test_rf_ohe, y_test_total, [\"F1\", \"MatthewsCorrelation\",\"Accuracy\"])\n",
    "\n",
    "preds = model.predict(X_test_rf_ohe)\n",
    "truths = y_test_total.to_numpy()\n",
    "\n",
    "printClassResults(preds,truths)\n",
    "\n",
    "tested_models.append(\"KNeighborsClassifier\")\n",
    "if fitness > best_fitness:\n",
    "    best_model = model\n",
    "    best_model_type = \"KNeighborsClassifier\"\n",
    "    best_model_hyperparams = hyper_params_dict\n",
    "    best_fitness = fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is:  0.9422\n",
      "The Precision is:  0.9876\n",
      "The Recall is:  0.9466\n",
      "The F1 score is:  0.9667\n",
      "The Matthews correlation coefficient is:  0.7573\n",
      "\n",
      "This is the Confusion Matrix\n",
      "     0    1\n",
      "0  117   12\n",
      "1   54  958\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegressionCV()\n",
    "lr_model.fit(X_train_rf, y_train_total)\n",
    "\n",
    "preds = lr_model.predict(X_test_rf)\n",
    "truths = y_test_total.to_numpy()\n",
    "\n",
    "printClassResults(preds,truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is:  0.9553\n",
      "The Precision is:  0.9804\n",
      "The Recall is:  0.9674\n",
      "The F1 score is:  0.9739\n",
      "The Matthews correlation coefficient is:  0.8198\n",
      "\n",
      "This is the Confusion Matrix\n",
      "     0    1\n",
      "0  139   19\n",
      "1   32  951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp_model = MLPClassifier()\n",
    "mlp_model.fit(X_train_rf, y_train_total)\n",
    "\n",
    "preds = mlp_model.predict(X_test_rf)\n",
    "truths = y_test_total.to_numpy()\n",
    "\n",
    "printClassResults(preds,truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "## Features\n",
    "### Using Random Forest Classifier for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "['nHM', 'F04', 'NssssC', 'nCb', 'F03', 'F02_CN', 'SpMax_L', 'SM6_L', 'SpPosA_B', 'SpMax_B', 'SM6_B', 'nX']\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_rf.columns))\n",
    "print(X_train_rf.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Possible Model Found from tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Model\n",
      "With hyperparams {'n_estimators': 129, 'criterion': 'log_loss', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0, 'bootstrap': True, 'oob_score': True, 'n_jobs': None, 'random_state': None, 'verbose': 0, 'warm_start': False, 'class_weight': None, 'ccp_alpha': 0, 'max_samples': None}\n",
      "The Accuracy is:  0.9676\n",
      "The Precision is:  0.9876\n",
      "The Recall is:  0.9746\n",
      "The F1 score is:  0.9811\n",
      "The Matthews correlation coefficient is:  0.8696\n",
      "\n",
      "This is the Confusion Matrix\n",
      "     0    1\n",
      "0  146   12\n",
      "1   25  958\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train_rf, y_train_total)\n",
    "\n",
    "preds = best_model.predict(X_test_rf)\n",
    "truths = y_test_total.to_numpy()\n",
    "\n",
    "print(f\"Tested Models - {str(tested_models)}\")\n",
    "print(f\"{best_model_type} Model\")\n",
    "print(f\"With hyperparams {best_model_hyperparams}\")\n",
    "printClassResults(preds,truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "### Random Forest Classifier\n",
    "Best Hyperparams = {'n_estimators': 129, 'criterion': 'log_loss', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0, 'bootstrap': True, 'oob_score': True, 'n_jobs': None, 'random_state': None, 'verbose': 0, 'warm_start': False, 'class_weight': None, 'ccp_alpha': 0, 'max_samples': None}\n",
    "<br>\n",
    "<br>\n",
    "The **Accuracy** is:  **0.9728**\n",
    "<br>\n",
    "The **Precision** is:  **0.9897**\n",
    "<br>\n",
    "The **Recall** is:  **0.9786**\n",
    "<br>\n",
    "The **F1 score** is:  **0.9841**\n",
    "<br>\n",
    "The **Matthews correlation coefficient** is:  **0.8911**\n",
    "<br>\n",
    "<br>\n",
    "This is the **Confusion Matrix**\n",
    "\n",
    "|   | 0   | 1   |\n",
    "|---|-----|-----|\n",
    "| 0 | 150 | 10  |\n",
    "| 1 | 21  | 960 |\n",
    "\n",
    "### SVM for Classification (SVC)\n",
    "Best Hyperparams = {'C': 4, 'kernel': 'rbf', 'degree': 3, 'gamma': 'scale', 'coef0': 0, 'shrinking': True, 'probability': False, 'tol': False, 'cache_size': 200, 'class_weight': None, 'verbose': False, 'max_iter': -1, 'decision_function_shape': 'ovr', 'break_ties': False, 'random_state': None}\n",
    "<br>\n",
    "<br>\n",
    "The **Accuracy** is:  **0.9606**\n",
    "<br>\n",
    "The **Precision** is:  **0.9928**\n",
    "<br>\n",
    "The **Recall** is:  **0.9620**\n",
    "<br>\n",
    "The **F1 score** is:  **0.9772**\n",
    "<br>\n",
    "The **Matthews correlation coefficient** is:  **0.8383**\n",
    "<br>\n",
    "<br>\n",
    "This is the **Confusion Matrix**\n",
    "\n",
    "|   | 0   | 1   |\n",
    "|---|-----|-----|\n",
    "| 0 | 133 | 7   |\n",
    "| 1 | 38  | 963 |\n",
    "\n",
    "### Naive Bayes\n",
    "#### Gaussian Naive Bayes\n",
    "Best Hyperparams = {'priors': None, 'var_smoothing': 0}\n",
    "<br>\n",
    "<br>\n",
    "The **Accuracy** is:  **0.9273**\n",
    "<br>\n",
    "The **Precision** is:  **0.9515**\n",
    "<br>\n",
    "The **Recall** is:  **0.9625**\n",
    "<br>\n",
    "The **F1 score** is:  **0.9570**\n",
    "<br>\n",
    "The **Matthews correlation coefficient** is:  **0.7224**\n",
    "<br>\n",
    "<br>\n",
    "This is the **Confusion Matrix**\n",
    "\n",
    "|   | 0   | 1   |\n",
    "|---|-----|-----|\n",
    "| 0 | 135 | 47  |\n",
    "| 1 | 36  | 923 |\n",
    "\n",
    "\n",
    "#### Bernoulli Naive Bayes\n",
    "Best Hyperparams = {'alpha': 1e-10, 'binarize': 1.75, 'fit_prior': True, 'class_prior': None}\n",
    "<br>\n",
    "<br>\n",
    "The **Accuracy** is:  **0.9150**\n",
    "<br>\n",
    "The **Precision** is:  **0.9608**\n",
    "<br>\n",
    "The **Recall** is:  **0.9405**\n",
    "<br>\n",
    "The **F1 score** is:  **0.9505**\n",
    "<br>\n",
    "The **Matthews correlation coefficient** is:  **0.6505**\n",
    "<br>\n",
    "<br>\n",
    "This is the **Confusion Matrix**\n",
    "\n",
    "|   | 0   | 1   |\n",
    "|---|-----|-----|\n",
    "| 0 | 112 | 38  |\n",
    "| 1 | 59  | 932 |\n",
    "\n",
    "### Gradient-Boost\n",
    "\n",
    "### Ada-Boost\n",
    "\n",
    "### K-Nearest Neighbours\n",
    "\n",
    "### Logistic Regression\n",
    "\n",
    "### Multi-Layer Perceptron\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "055142e5cf66ed8ee87e97d9d29944a505c8696ace08c4c3475747b47f85af0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
