{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, normalize\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix, accuracy_score\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "def printClassResults(truth, preds):\n",
    "    print(\"The Accuracy is: %7.4f\" % accuracy_score(truth, preds))\n",
    "    print(\"The Precision is: %7.4f\" % precision_score(truth, preds, pos_label='RB'))\n",
    "    print(\"The Recall is: %7.4f\" % recall_score(truth, preds, pos_label='RB'))\n",
    "    print(\"The F1 score is: %7.4f\" % f1_score(truth, preds, pos_label='RB'))\n",
    "    print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(truth, preds))\n",
    "    print()\n",
    "    print(\"This is the Confusion Matrix\")\n",
    "    print(pd.DataFrame(confusion_matrix(truth, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "41\n",
      "     nHM F04 NssssC nCb nO F03 nN_N nArNO2 nCRX3 B01  ...       SpMax_A  \\\n",
      "0      0   0      0   0  4   0    0      0     0   0  ...  2.805893e-14   \n",
      "1      0   0      0   0  4   0    0      0     0   0  ...  6.371135e-03   \n",
      "2      0   0      0   2  2   0    0      0     0   0  ...  3.818507e-01   \n",
      "3      0   0      0   2  2   0    0      0     0   0  ...  5.995285e-01   \n",
      "4      0   0      0   0  2   0    0      0     0   0  ... -1.693350e+00   \n",
      "...   ..  ..    ...  .. ..  ..  ...    ...   ...  ..  ...           ...   \n",
      "4559   0   0      0   0  2   0    0      0     0   0  ...  2.805893e-14   \n",
      "4560   0   0      0   0  4   0    0      0     0   0  ...  5.062141e-01   \n",
      "4561   0   0      4   0  4   0    0      0     0   0  ...  1.756083e+00   \n",
      "4562   0   0      0   0  1   0    0      0     0   0  ... -9.546767e-02   \n",
      "4563   0   0      0   1  0   0    0      0     0   0  ... -5.648479e-01   \n",
      "\n",
      "      Psi_i_1d       SdO     TI2_L      nCrt       SpMax_B       Psi_i_A  \\\n",
      "0    -0.394796  1.045124 -0.154799 -0.100618  4.501572e-15  2.199528e+00   \n",
      "1     0.322174  1.041655 -0.286046 -0.100618 -2.023558e-01  2.655378e+00   \n",
      "2     0.345826 -0.983609 -0.877598 -0.100618  4.501572e-15  4.854090e-01   \n",
      "3     0.135448  0.089273 -0.524779 -0.100618  2.189738e-01  2.673958e-01   \n",
      "4    -0.028260 -0.022447 -0.692739 -0.100618  4.501572e-15  2.137955e+00   \n",
      "...        ...       ...       ...       ...           ...           ...   \n",
      "4559  3.665573 -0.983609 -0.512447 -0.100618  4.501572e-15  4.555437e-01   \n",
      "4560  0.046197 -0.983609  0.342203 -0.100618 -4.156412e-01 -1.674584e-14   \n",
      "4561  0.046197 -0.983609 -0.119578  3.085114 -2.512191e-02 -1.017780e+00   \n",
      "4562 -0.392821 -0.983609 -0.824601 -0.100618 -8.761166e-01 -8.877811e-01   \n",
      "4563  0.858349 -0.983609 -0.918320 -0.100618  4.501572e-15 -8.038583e-01   \n",
      "\n",
      "         SM6_B            nX  Biodegradable  \n",
      "0    -0.080245 -1.602862e-01             RB  \n",
      "1    -0.127823  2.612766e-17             RB  \n",
      "2    -0.140206 -1.602862e-01             RB  \n",
      "3     0.155137  2.612766e-17             RB  \n",
      "4    -1.023157  2.612766e-17             RB  \n",
      "...        ...           ...            ...  \n",
      "4559 -2.103951 -1.602862e-01             RB  \n",
      "4560  0.295168 -1.602862e-01            NRB  \n",
      "4561  0.546310 -1.602862e-01            NRB  \n",
      "4562 -1.127780 -1.602862e-01             RB  \n",
      "4563 -0.535615  2.612766e-17             RB  \n",
      "\n",
      "[4564 rows x 42 columns]\n",
      "(4564, 42)\n",
      "(889, 42)\n"
     ]
    }
   ],
   "source": [
    "initial_dataset = pd.read_csv(\"biodegradable_a.csv\").sample(frac=1).reset_index(drop=True)\n",
    "total_len, _ = initial_dataset.shape\n",
    "\n",
    "# NOTE - NO INDEPENDENT VALIDATION SET !!!\n",
    "\n",
    "# Total with means\n",
    "#categorical = ['int16', 'int32', 'int64']\n",
    "#biodegradable = ['object']\n",
    "#numerical = ['float16', 'float32', 'float64']\n",
    "\n",
    "class_cols = [col for col in initial_dataset.drop(\"Biodegradable\", axis=1) if initial_dataset[col].apply(lambda x: x % 1 == 0).all()]\n",
    "num_cols = [col for col in initial_dataset.drop(\"Biodegradable\", axis=1) if initial_dataset[col].apply(lambda x: x % 1 != 0).any()]\n",
    "\n",
    "print(len(class_cols) + len(num_cols))\n",
    "print(len(initial_dataset.drop(\"Biodegradable\", axis=1).columns))\n",
    "\n",
    "total_categorical_dataset = initial_dataset[class_cols]\n",
    "#total_categorical_dataset = total_categorical_dataset.fillna(total_categorical_dataset.mode())\n",
    "total_categorical_dataset = total_categorical_dataset.fillna(-1)\n",
    "total_categorical_dataset = total_categorical_dataset.astype(int).astype(object).astype(str)\n",
    "#print(total_categorical_dataset)\n",
    "\n",
    "total_numerical_dataset = initial_dataset[num_cols]\n",
    "total_numerical_dataset = total_numerical_dataset.fillna(total_numerical_dataset.mean())\n",
    "\n",
    "total_biodegradable = initial_dataset[\"Biodegradable\"]\n",
    "#total_biodegradable = initial_dataset.select_dtypes(include=biodegradable)\n",
    "#total_biodegradable = total_biodegradable.fillna(\"\")\n",
    "\n",
    "# Scale numerical data\n",
    "# https://scikit-learn.org/stable/modules/preproce\n",
    "#print(total_numerical_dataset)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "total_numerical_dataset = pd.DataFrame(scaler.fit_transform(total_numerical_dataset),\n",
    "             columns=total_numerical_dataset.columns, index=total_numerical_dataset.index)\n",
    "\n",
    "\n",
    "#total_numerical_dataset = pd.DataFrame(normalize(total_numerical_dataset, norm='l2', axis=1, copy=True, return_norm=False),\n",
    "#             columns=total_numerical_dataset.columns, index=total_numerical_dataset.index)\n",
    "\n",
    "#print(total_numerical_dataset)\n",
    "#\n",
    "total_dataset = pd.concat([total_categorical_dataset, total_numerical_dataset,total_biodegradable], axis=1)\n",
    "#total_dataset.dropna(0)\n",
    "print(total_dataset)\n",
    "\n",
    "total_len, _ = total_dataset.shape\n",
    "train_dataset_len = round(total_len * 0.75)\n",
    "\n",
    "dataset_train = total_dataset[0:train_dataset_len]\n",
    "dataset_test = total_dataset[train_dataset_len:total_len]\n",
    "\n",
    "print(total_dataset.shape)\n",
    "\n",
    "# Removal of None/NaN vals\n",
    "dropna_dataset = initial_dataset.dropna()\n",
    "\n",
    "dropna_len, _ = dropna_dataset.shape\n",
    "model_dropna_len = round(total_len * 0.75)\n",
    "\n",
    "dropna_train = dropna_dataset[0:model_dropna_len]\n",
    "dropna_test = dropna_dataset[model_dropna_len:dropna_len]\n",
    "\n",
    "print(dropna_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['nHM', 'F04', 'NssssC', 'nCb', 'nO', 'F03', 'nN_N', 'nArNO2', 'nCRX3',\n",
      "       'B01', 'B03', 'N_073', 'B04', 'C_026', 'F02_CN', 'nHDon', 'nN',\n",
      "       'nArCOOR', 'SpMax_L', 'J_Dz(e)', 'F01', 'C', 'nCp', 'SdssC', 'HyWi_B',\n",
      "       'LOC', 'SM6_L', 'F03_CO', 'Me', 'Mi', 'SpPosA_B', 'nCIR', 'SpMax_A',\n",
      "       'Psi_i_1d', 'SdO', 'TI2_L', 'nCrt', 'SpMax_B', 'Psi_i_A', 'SM6_B', 'nX',\n",
      "       'Biodegradable'],\n",
      "      dtype='object')\n",
      "Index(['SpMax_L', 'J_Dz(e)', 'nHM', 'F01', 'F04', 'NssssC', 'nCb', 'C', 'nCp',\n",
      "       'nO', 'F03', 'SdssC', 'HyWi_B', 'LOC', 'SM6_L', 'F03_CO', 'Me', 'Mi',\n",
      "       'nN_N', 'nArNO2', 'nCRX3', 'SpPosA_B', 'nCIR', 'B01', 'B03', 'N_073',\n",
      "       'SpMax_A', 'Psi_i_1d', 'B04', 'SdO', 'TI2_L', 'nCrt', 'C_026', 'F02_CN',\n",
      "       'nHDon', 'SpMax_B', 'Psi_i_A', 'nN', 'SM6_B', 'nArCOOR', 'nX',\n",
      "       'Biodegradable'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(total_dataset.columns)\n",
    "print(dropna_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Model with replaced values when NaN, and discarding the dropped NaN values dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     nHM F04 NssssC nCb nO F03 nN_N nArNO2 nCRX3 B01  ...      nCIR  \\\n",
      "0      0   0      0   0  4   0    0      0     0   0  ... -0.302031   \n",
      "1      0   0      0   0  4   0    0      0     0   0  ... -0.302031   \n",
      "2      0   0      0   2  2   0    0      0     0   0  ...  0.117354   \n",
      "3      0   0      0   2  2   0    0      0     0   0  ...  0.117354   \n",
      "4      0   0      0   0  2   0    0      0     0   0  ... -0.302031   \n",
      "...   ..  ..    ...  .. ..  ..  ...    ...   ...  ..  ...       ...   \n",
      "3418   0   0      0   1  1   0    0      0     0   0  ...  0.117354   \n",
      "3419   0   0      0   0  0   0    0      0     0   0  ... -0.302031   \n",
      "3420   0   0      0   0  2   1    0      0     0   0  ... -0.302031   \n",
      "3421   1   3      0   1  2   3    0      0     0   0  ...  0.117354   \n",
      "3422   0   0      0   1  1   0    0      0     0   0  ...  0.117354   \n",
      "\n",
      "           SpMax_A  Psi_i_1d       SdO     TI2_L      nCrt       SpMax_B  \\\n",
      "0     2.805893e-14 -0.394796  1.045124 -0.154799 -0.100618  4.501572e-15   \n",
      "1     6.371135e-03  0.322174  1.041655 -0.286046 -0.100618 -2.023558e-01   \n",
      "2     3.818507e-01  0.345826 -0.983609 -0.877598 -0.100618  4.501572e-15   \n",
      "3     5.995285e-01  0.135448  0.089273 -0.524779 -0.100618  2.189738e-01   \n",
      "4    -1.693350e+00 -0.028260 -0.022447 -0.692739 -0.100618  4.501572e-15   \n",
      "...            ...       ...       ...       ...       ...           ...   \n",
      "3418  3.374858e-01  0.135448 -0.983609 -0.294092  0.000000  4.653168e-02   \n",
      "3419  2.805893e-14  0.053719 -0.983609  1.205648 -0.100618 -1.254668e+00   \n",
      "3420 -1.155604e+00 -1.719701 -0.007593 -0.399395 -0.100618 -3.474670e-01   \n",
      "3421  1.082130e+00  0.052572  1.430358  0.044081 -0.100618  2.251567e+00   \n",
      "3422  4.087575e-01  0.233468 -0.983609 -0.646042 -0.100618  9.463013e-02   \n",
      "\n",
      "           Psi_i_A     SM6_B            nX  \n",
      "0     2.199528e+00 -0.080245 -1.602862e-01  \n",
      "1     2.655378e+00 -0.127823  2.612766e-17  \n",
      "2     4.854090e-01 -0.140206 -1.602862e-01  \n",
      "3     2.673958e-01  0.155137  2.612766e-17  \n",
      "4     2.137955e+00 -1.023157  2.612766e-17  \n",
      "...            ...       ...           ...  \n",
      "3418 -4.966114e-01 -0.045036  2.612766e-17  \n",
      "3419 -1.827767e+00 -0.612816 -1.602862e-01  \n",
      "3420 -1.674584e-14 -0.432198 -1.602862e-01  \n",
      "3421 -1.573457e-01  1.501413  2.612766e-17  \n",
      "3422 -8.847182e-01 -0.120659 -1.602862e-01  \n",
      "\n",
      "[3423 rows x 41 columns]\n",
      "0        RB\n",
      "1        RB\n",
      "2        RB\n",
      "3        RB\n",
      "4        RB\n",
      "       ... \n",
      "3418     RB\n",
      "3419     RB\n",
      "3420     RB\n",
      "3421    NRB\n",
      "3422     RB\n",
      "Name: Biodegradable, Length: 3423, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_train_total = dataset_train.drop([\"Biodegradable\"], axis=1)\n",
    "y_train_total = dataset_train.Biodegradable\n",
    "print(X_train_total)\n",
    "print(y_train_total)\n",
    "\n",
    "X_test_total = dataset_test.drop([\"Biodegradable\"], axis=1)\n",
    "y_test_total = dataset_test.Biodegradable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Random Forests for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SelectFromModel(estimator=RandomForestClassifier(), max_features=12)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=RandomForestClassifier(), max_features=12)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(), max_features=12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://towardsdatascience.com/feature-selection-using-random-forest-26d7b747597f\n",
    "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100), max_features=12) # when no max_features are specified, seems to vary between 12 and 15\n",
    "sel.fit(X_train_total, y_train_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True False  True False False False False False False\n",
      " False False  True False  True False  True False False False False False\n",
      " False False False False False False  True False  True False False False\n",
      " False False False  True  True]\n",
      "12\n",
      "Index(['nHM', 'F04', 'NssssC', 'nCb', 'F03', 'F02_CN', 'nN', 'SpMax_L',\n",
      "       'SpPosA_B', 'SpMax_A', 'SM6_B', 'nX'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(sel.get_support())\n",
    "selected_feat= X_train_total.columns[(sel.get_support())]\n",
    "print(len(selected_feat))\n",
    "print(selected_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     nHM F04 NssssC nCb F03 F02_CN nN   SpMax_L  SpPosA_B       SpMax_A  \\\n",
      "0      0   0      0   0   0      0  0 -0.297450 -0.989182  2.805893e-14   \n",
      "1      0   0      0   0   0      0  0  0.245742 -1.628388  6.371135e-03   \n",
      "2      0   0      0   2   0      0  0  0.371020  0.224842  3.818507e-01   \n",
      "3      0   0      0   2   0      0  0  0.441189  0.584927  5.995285e-01   \n",
      "4      0   0      0   0   0      0  0 -0.945053 -1.685966 -1.693350e+00   \n",
      "...   ..  ..    ...  ..  ..    ... ..       ...       ...           ...   \n",
      "3418   0   0      0   1   0      0  0  0.162363  0.947616  3.374858e-01   \n",
      "3419   0   0      0   0   0      0  0 -1.244933  0.086245  2.805893e-14   \n",
      "3420   0   0      0   0   1      1  1 -0.706745 -0.173784 -1.155604e+00   \n",
      "3421   1   3      0   1   3      2  1  1.702623  0.598555  1.082130e+00   \n",
      "3422   0   0      0   1   0      0  0  0.262735  1.378860  4.087575e-01   \n",
      "\n",
      "         SM6_B            nX  \n",
      "0    -0.080245 -1.602862e-01  \n",
      "1    -0.127823  2.612766e-17  \n",
      "2    -0.140206 -1.602862e-01  \n",
      "3     0.155137  2.612766e-17  \n",
      "4    -1.023157  2.612766e-17  \n",
      "...        ...           ...  \n",
      "3418 -0.045036  2.612766e-17  \n",
      "3419 -0.612816 -1.602862e-01  \n",
      "3420 -0.432198 -1.602862e-01  \n",
      "3421  1.501413  2.612766e-17  \n",
      "3422 -0.120659 -1.602862e-01  \n",
      "\n",
      "[3423 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train_rf = X_train_total[X_train_total.columns[(sel.get_support())]]\n",
    "X_test_rf = X_test_total[X_test_total.columns[(sel.get_support())]]\n",
    "\n",
    "print(X_train_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing a Random Forest Model for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is:  0.9649\n",
      "The Precision is:  0.9893\n",
      "The Recall is:  0.9685\n",
      "The F1 score is:  0.9788\n",
      "The Matthews correlation coefficient is:  0.8800\n",
      "\n",
      "This is the Confusion Matrix\n",
      "     0    1\n",
      "0  179   10\n",
      "1   30  922\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators = 100)\n",
    "rf_model.fit(X_train_rf, y_train_total)\n",
    "\n",
    "preds = rf_model.predict(X_test_rf)\n",
    "truths = y_test_total.to_numpy()\n",
    "\n",
    "printClassResults(preds,truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Random Forest Model for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9293193711555747---(130, 'entropy', None, 2, 1, 0, 'sqrt', None, 0, True, False, None, None, 0, False, None, 0, None)\n",
      "0.9293193711555747---(150, 'gini', None, 2, 1, 0, 'sqrt', None, 0, True, False, None, None, 0, False, None, 0, None)\n",
      "0.9293193711555747---(200, 'gini', None, 2, 1, 0, 'sqrt', None, 0, True, False, None, None, 0, False, None, 0, None)\n",
      "Max Fitness = 0.9165753789651077 using the mean of ['F1', 'MatthewsCorrelation']\n",
      "Best Hyperparams = {'n_estimators': 120, 'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0, 'bootstrap': True, 'oob_score': False, 'n_jobs': None, 'random_state': None, 'verbose': 0, 'warm_start': False, 'class_weight': None, 'ccp_alpha': 0, 'max_samples': None}\n",
      "The Accuracy is:  0.9649\n",
      "The Precision is:  0.9903\n",
      "The Recall is:  0.9675\n",
      "The F1 score is:  0.9788\n",
      "The Matthews correlation coefficient is:  0.8798\n",
      "\n",
      "This is the Confusion Matrix\n",
      "     0    1\n",
      "0  178    9\n",
      "1   31  923\n"
     ]
    }
   ],
   "source": [
    "def rf_optimization(X_train: pd.DataFrame, y_train: pd.DataFrame, X_test: pd.DataFrame, y_test: pd.DataFrame, target_classes: list = [\"F1\"]) -> Tuple[RandomForestClassifier, np.array]:\n",
    "    \n",
    "    assert \"F1\" in target_classes or \"Accuracy\" in target_classes or \"Precision\" in target_classes or \"Recall\" in target_classes or \"MatthewsCorrelation\" in target_classes\n",
    "\n",
    "    n_estimators = [100,120,130,150,200]\n",
    "    #criterion = [\"gini\"]\n",
    "    criterion = [\"gini\",\"entropy\",\"log_loss\"]\n",
    "    max_depth = [None]\n",
    "    min_samples_split = [2]\n",
    "    min_samples_leaf = [1]\n",
    "    min_weight_fraction_leaf = [0]\n",
    "    #max_features = [\"sqrt\"]\n",
    "    max_features = [\"sqrt\",\"log2\", None]\n",
    "    max_leaf_nodes = [None]\n",
    "    min_impurity_decrease = [0]\n",
    "    bootstrap = [True]\n",
    "    oob_score = [False]\n",
    "    n_jobs = [None]\n",
    "    random_state = [None]\n",
    "    verbose = [0]\n",
    "    warm_start = [False]\n",
    "    class_weight = [None]\n",
    "    ccp_alpha = [0]\n",
    "    max_samples = [None]\n",
    "\n",
    "    rf_hyperparams = itertools.product(\n",
    "                                        n_estimators,\n",
    "                                        criterion,\n",
    "                                        max_depth,\n",
    "                                        min_samples_split,\n",
    "                                        min_samples_leaf,\n",
    "                                        min_weight_fraction_leaf,\n",
    "                                        max_features,\n",
    "                                        max_leaf_nodes,\n",
    "                                        min_impurity_decrease,\n",
    "                                        bootstrap,\n",
    "                                        oob_score,\n",
    "                                        n_jobs,\n",
    "                                        random_state,\n",
    "                                        verbose,\n",
    "                                        warm_start,\n",
    "                                        class_weight,\n",
    "                                        ccp_alpha,\n",
    "                                        max_samples\n",
    "                                    )\n",
    "\n",
    "    best_fitness = -99999\n",
    "    best_model = None\n",
    "    best_hyper_params = None\n",
    "\n",
    "    for hyper_param in rf_hyperparams:\n",
    "\n",
    "        n_estimators,\\\n",
    "            criterion,\\\n",
    "            max_depth,\\\n",
    "            min_samples_split,\\\n",
    "            min_samples_leaf,\\\n",
    "            min_weight_fraction_leaf,\\\n",
    "            max_features,\\\n",
    "            max_leaf_nodes,\\\n",
    "            min_impurity_decrease,\\\n",
    "            bootstrap,\\\n",
    "            oob_score,\\\n",
    "            n_jobs,\\\n",
    "            random_state,\\\n",
    "            verbose,\\\n",
    "            warm_start,\\\n",
    "            class_weight,\\\n",
    "            ccp_alpha,\\\n",
    "            max_samples\\\n",
    "                = hyper_param\n",
    "\n",
    "        model = RandomForestClassifier(\n",
    "                        n_estimators=n_estimators,\n",
    "                        criterion=criterion,\n",
    "                        max_depth=max_depth,\n",
    "                        min_samples_split=min_samples_split,\n",
    "                        min_samples_leaf=min_samples_leaf,\n",
    "                        min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                        max_features=max_features,\n",
    "                        max_leaf_nodes=max_leaf_nodes,\n",
    "                        min_impurity_decrease=min_impurity_decrease,\n",
    "                        bootstrap=bootstrap,\n",
    "                        oob_score=oob_score,\n",
    "                        n_jobs=n_jobs,\n",
    "                        random_state=random_state,\n",
    "                        verbose=verbose,\n",
    "                        warm_start=warm_start,\n",
    "                        class_weight=class_weight,\n",
    "                        ccp_alpha=ccp_alpha,\n",
    "                        max_samples=max_samples\n",
    "                    )\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        truths = y_test.to_numpy()\n",
    "\n",
    "        fitness = 0\n",
    "\n",
    "        for target_class in target_classes:\n",
    "            if target_class == \"F1\":\n",
    "                fitness += f1_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"Accuracy\":\n",
    "                fitness += accuracy_score(truths, preds)\n",
    "            elif target_class == \"Precision\":\n",
    "                fitness += precision_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"Recall\":\n",
    "                fitness += recall_score(truths, preds, pos_label='RB')\n",
    "            elif target_class == \"MatthewsCorrelation\":\n",
    "                fitness += matthews_corrcoef(truths, preds)\n",
    "            else:\n",
    "                raise Exception(f\"Unkown Metric {target_class}\")\n",
    "        \n",
    "        fitness = fitness / len(target_classes)\n",
    "\n",
    "        if fitness > best_fitness:\n",
    "            best_model = model\n",
    "            best_fitness = fitness\n",
    "            best_hyper_params = hyper_param\n",
    "        elif fitness == best_fitness:\n",
    "            print(str(fitness) + \"---\" + str(hyper_param))\n",
    "\n",
    "    \n",
    "    print(f\"Max Fitness = {str(fitness)} using the mean of {str(target_classes)}\")\n",
    "\n",
    "    n_estimators,\\\n",
    "            criterion,\\\n",
    "            max_depth,\\\n",
    "            min_samples_split,\\\n",
    "            min_samples_leaf,\\\n",
    "            min_weight_fraction_leaf,\\\n",
    "            max_features,\\\n",
    "            max_leaf_nodes,\\\n",
    "            min_impurity_decrease,\\\n",
    "            bootstrap,\\\n",
    "            oob_score,\\\n",
    "            n_jobs,\\\n",
    "            random_state,\\\n",
    "            verbose,\\\n",
    "            warm_start,\\\n",
    "            class_weight,\\\n",
    "            ccp_alpha,\\\n",
    "            max_samples\\\n",
    "                = best_hyper_params\n",
    "\n",
    "    best_hyper_params_dict = {\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"criterion\": criterion,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"min_samples_split\": min_samples_split,\n",
    "        \"min_samples_leaf\": min_samples_leaf,\n",
    "        \"min_weight_fraction_leaf\": min_weight_fraction_leaf,\n",
    "        \"max_features\": max_features,\n",
    "        \"max_leaf_nodes\": max_leaf_nodes,\n",
    "        \"min_impurity_decrease\": min_impurity_decrease,\n",
    "        \"bootstrap\": bootstrap,\n",
    "        \"oob_score\": oob_score,\n",
    "        \"n_jobs\": n_jobs,\n",
    "        \"random_state\": random_state,\n",
    "        \"verbose\": verbose,\n",
    "        \"warm_start\": warm_start,\n",
    "        \"class_weight\": class_weight,\n",
    "        \"ccp_alpha\": ccp_alpha,\n",
    "        \"max_samples\": max_samples\n",
    "    }\n",
    "\n",
    "    print(f\"Best Hyperparams = {str(best_hyper_params_dict)}\")\n",
    "    return best_model, best_fitness, best_hyper_params_dict\n",
    "\n",
    "\n",
    "model, fitness, hyper_params_dict = rf_optimization(X_train_rf, y_train_total, X_test_rf, y_test_total, [\"F1\", \"MatthewsCorrelation\"])\n",
    "\n",
    "preds = model.predict(X_test_rf)\n",
    "truths = y_test_total.to_numpy()\n",
    "\n",
    "printClassResults(preds,truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "055142e5cf66ed8ee87e97d9d29944a505c8696ace08c4c3475747b47f85af0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
